[
["index.html", "R Programming for Research Online course book, ERHS 535", " R Programming for Research Colorado State University, ERHS 535 Brooke Anderson and Rachel Severson 2016-09-09 Online course book, ERHS 535 This is the online book for Colorado State University’s ERHS 535 R Programming for Research course. This book includes course information, course notes, links to download pdfs of lecture slides, in-course exercises, homework assignments, and vocabulary lists for quizzes for this course. Because this is my first semester teaching the course with this online book, it will be evolving throughout the semester, as we get to new material. The book can be downloaded as a pdf or an eBook. To download it, use the “download” button in the top menu bar of the webpage. You can also search the book using the magnifying glass button in the top menu bar. "],
["course-information.html", "Course information 0.1 Course overview 0.2 Time and place 0.3 Detailed schedule 0.4 Grading 0.5 Weekly in-course group exercises 0.6 Course set-up 0.7 Helpful books for learning R", " Course information Download a pdf of the lecture slides covering this topic. 0.1 Course overview This document provides the course notes for Colorado State University’s ERHS 535 course for Fall 2016. The course offers in-depth instruction on data collection, data management, programming, and visualization, using data examples relevant to academic research. 0.2 Time and place This course meets in Room 120 of the Environmental Health Building on Mondays and Wednesdays, 10:00 am–12:00 pm. Exceptions to these meeting times are: There will be no meeting on Wednesday, Aug. 31. There will be no meeting on Labor Day (Monday, Sept. 5). To make up for missing class on Aug. 31, we will have a supplemental class on Friday, Sept. 9, 10:00 am–12:00 pm. You will not lose attendance points if you cannot attend this class, but will be responsible for the material covered. There are no course meetings the week of Thanksgiving. 0.3 Detailed schedule Here is a more detailed view of the schedule for this course for Fall 2016: Dates Level Lecture content Graded items Aug. 22, 24 Preliminary R Preliminaries Aug. 29 Basic Entering and cleaning data Sept. 7, Sept. 9* Basic Exploring data Quiz (W) Sept. 12, 14 Basic Reporting data results Quiz (M), HW #1 (W) Sept. 19, 21 Basic Reproducible Research Quiz (M) Sept. 26, 28 Intermediate Entering and cleaning data Quiz (M), HW #2 (W) Oct. 3, 5 Intermediate Exploring data Quiz (M) Oct. 10, 12 Intermediate Reporting data results Quiz (M), HW #3 (W) Oct. 17, 19 Intermediate Reproducible Research Quiz (M) Oct. 24, 26 Advanced Entering and cleaning data Quiz (M), HW #4 (W) Oct. 31, Nov. 2 Advanced Exploring data Project proposal (M) Nov. 7, 9 Advanced Reporting data results HW #5 (W) Nov. 14, 16 Advanced Mapping in R Nov. 28, 30 Advanced Package development 1 HW #6 (W) Dec. 5, 7 Advanced Package development 2 Project draft (M) Week of Dec. 12 Group presentations Final project (M) 0.4 Grading Course grades will be determined by the following five components: Assessment component Percent of grade Final group project 30 Weekly in-class quizzes, weeks 3-10 25 Homework 25 Attendance and class participation 10 Weekly in-course group exercises 10 0.4.1 Attendance and class participation Because so much of the learning for this class is through interactive work in class, it is critical that you come to class. Out of a possible 10 points for class attendance, you will get: 10 points if you attend all classes 8 points if you miss one class 6 points if you miss two classes 4 points if you miss three classes 2 points if you miss four classes 0 points if you miss five or more classes You can get two extra credit attendance points (i.e., make up for a missed class) by attending the seminar that Yihui Xie will give on Sept. 23 at 4:00 pm for the Statistics Department in Weber 237. 0.5 Weekly in-course group exercises Part of each class will be spent doing in-course group exercises. Ten points of your final grade will be based on your participation in these exercises. As long as you are in class and participate in these exercises, you will get full credit for this component. If you miss a class, to get credit towards this component of your grade, you will need to turn in a one-page document describing what you learned from doing the in-course exercise on your own time. All in-class exercises are included in the online course book at the end of the chapter on the associated material. 0.5.1 In-class quizzes You will have eight total in-class quizzes. You will have one for each of the Week 2–10 class meetings. There will be at least 10 questions per quiz. You will get 1/3 point for each correct answer. If you do the math, you can get full credit for this if you get at least 75% of your answers right. You can not get more than the maximum of 25 points for this component– once you reach 25 points on quizzes, you will have achieved full credit for the quiz component of the course grade. All quiz questions will be multiple choice, matching, or some other form of “close-answered” question (i.e., no open-response-style questions). You can not make up a quiz for a class period you missed. You can still get full credit on your total possible quiz points if you miss a class, but it means you will have to work harder and get more questions right for days you are in class. Because grading format for these quizzes allows for you to miss some questions and still get the full quiz credit for the course, I will not ever re-consider the score you got on a previous quiz, give points back for a wrong answer on a poorly-worded question, etc. However, if a lot of people got a particular question wrong, I will be sure to cover it in the next class period. Also, especially if a question was poorly worded and caused confusion, I will work a similar question into a future quiz– in addition to the 10 guaranteed questions for that quiz– so every student will have the chance to get an extra 1/3 point of credit for the question. The “Vocabulary” appendix of our online book has the list of material for which you will be responsible for this quiz. Most of the functions and concepts will have been covered in class, but some may not. You are responsible for going through the list and, if there are things you don’t know or remember from class, learning them. To do this, you can use help functions in R, Google, StackOverflow, books on R, ask a friend, and any other resource you can find. In general, using R frequently in your research or other coursework will help you to prepare and do well on these quizzes. 0.5.2 Homework There will be six homework assignments, starting a few weeks into the course and then due approximately every two weeks (see the detailed schedule in the online course book for exact due dates). Homeworks should be done individually. You will get many chances to work with others during in-course exercises and your final group project, but these homeworks should be a chance to assess how well you understand and can use the course material on your own. Homeworks will be graded for correctness, but some partial credit will be given for questions you try but fail to answer correctly. If you can’t completely do a required task, be sure to show and explain what you tried to do to complete it. Homework is due by the start of class on the due date. Your grade will be reduced by 10 points for each day it is late, and will receive no credit if it is late by over a week. 0.5.3 Final group project You will do the final group project in groups of 2–3. The final product will be a statistical blog post-style article of 1,500 words or less and an accompanying Shiny web application. Come up with an interesting question you’d love to get the answer to that you think you can find data to help you answer. You will need to use the data you find, and R, to write your article. The final product will be a Word document created from an RMarkdown file and an accompanying Shiny web application. Here are some articles to give you an idea of the style and content for this project: Does Christmas come earlier each year? Hilary: the most poisoned baby name in US history Every Guest Jon Stewart Ever Had On “The Daily Show” Should Travelers Avoid Flying Airlines That Have Had Crashes in the Past? Billion-Dollar Billy Beane You will have in-class group work time during weeks 10–15 to work on this. This project will also require some work with your group outside of class. You will be able to get feedback from me through weekly informal written reports in these weeks. I will also provide feedback and help during the in-class group work time. The final group project will be graded with A through F, with the following point values (out of 30 possible): 30 points for an A 25 points for a B 20 points for a C 15 points for a D 10 points for an F If you turn nothing in, you will get 0 points. We will discuss expectations for this project, create groups, etc. around the middle of the semester. The focus for this will be on finding, cleaning, and using good data to answer an interesting question, and on presenting, summarizing, and explaining the data well. 0.6 Course set-up Please be sure you have the latest version of R and RStudio installed. Also, be sure to sign up for a free GitHub account. 0.7 Helpful books for learning R There are three publishers that are leaders in good books for learning R: O’Reilly No Starch Press Springer Some particular books you might want to check out: R for Data Science R for Dummies R in a Nutshell R Cookbook R Graphics Cookbook A Beginner’s Guide to R Roger Peng’s Leanpub books Books that other students have found useful include: Introductory R by Robert J. Knell "],
["r-preliminaries.html", "Chapter 1 R Preliminaries 1.1 R and R Studio 1.2 The “package” system 1.3 Basic code conventions of R 1.4 R’s most basic object types 1.5 Using R functions 1.6 In-course Exercise", " Chapter 1 R Preliminaries Download a pdf of the lecture slides covering this topic. 1.1 R and R Studio 1.1.1 What is R? R in an open-source programming language that evolved from the S language. The S language was developed at Bell Labs in the 1970s, which is the same place (and about the same time) that the C programming language was developed. R itself was developed in the 1990s–2000s at the University of Auckland. It is open-source software, freely and openly distributed under the GNU General License. The base version of R that you download when you install R on your computer includes the critical code for running R, but you can also install and run “packages” that people all over the world have developed to extend R. With new developments, R is becoming more and more useful for a variety of programming tasks. However, where it really shines is in working with data and doing statistical analysis. R is currently popular in a number of fields, including: Statistics Machine learning Data journalism / data analysis R has some of the same strengths (quick and easy to code, interfaces well with other languages, easy to work interactively) and weaknesses (slower than compiled languages) as Python. For data-related tasks, R and Python are fairly neck-and-neck. However, R is still the first choice of statisticians in most fields, so I would argue that R has a an advantage if you want to have access to cutting-edge statistical methods. “The best thing about R is that it was developed by statisticians. The worst thing about R is that… it was developed by statisticians.” -Bo Cowgill, Google, at the Bay Area R Users Group 1.1.2 Open-source software R is open-source software. Many other popular statistical programming languages, conversely, are proprietary. It’s useful to know what it means for software to be “open-source”, both conceptually and in terms of how you will be able to use and add to R in your own work. R is free, and it’s tempting to think of open-source software just as “free software”. Things, however, are a little more subtle than that. It helps to consider some different meanings of the word “free”. “Free” can mean: Gratis: Free as in beer Libre: Free as in speech Open-source software software is the libre type of free. This means that, with software that is open-source, you can: Access all of the code that makes up the software Change the code as you’d like for your own applications Build on the code with your own extensions Share the software and its code, as well as your extensions, with others In practice, this means that, once you are familiar with the software, you can dig deeply into the code to figure out exactly how it’s performing certain tasks. This can be useful for finding bugs and eliminating bugs, and also can help researchers figure out if there are any limitations in how the code works for their specific research. It also means that you can build your own software on top of existing R software and its extensions. I explain a bit more about R packages a bit later, but this open-source nature of R (and other languages, including Python) has created a large community of people worldwide who develop and share extensions to R. As a result, you can pull in packages that let you do all kinds of things in R, like visualizing Tweets, cleaning up accelerometer data, analyzing complex surveys, fitting maching learning models, and a wealth of other cool things. 1.1.3 What is RStudio? To get the R software, you’ll download R from the R Project for Statistical Computing. This is enough for you to use R on your own computer. However, I would suggest one additional, free piece of software to improve your experience while working with R, RStudio. RStudio is an integrated development environment (IDE) for R. This basically means that it provides you an interface for running R and coding in R, with a lot of nice extras that will make your life easier. You download RStudio separately from R– you’ll want to download and install R itself first, and then you can download RStudio. You want the Desktop version with the free license. The company that develops this IDE is a fantastic contributer to the global R community. RStudio currently: Develops and freely provides the RStudio IDE Provides excellent resources for learning and using R (cheatsheets, ) Is producing some of the most-used R packages Employs some of the top people in R development R has been advancing by leaps in bounds in terms of what it can do and the elegance with which it does it, in large part because of the enormous contributions of people involved with RStudio. 1.1.4 Setting up If do not already have them, you will need to download and install both R and RStudio. Go to CRAN and download the latest version of R for your system. Install. Go to the RStudio download page and download the latest version of RStudio for your system. Install. Defaults should be fine for everything when you install both R and RStudio. You will want the latest stable version, rather than the development version, for this course. 1.2 The “package” system 1.2.1 R packages Your original download of R is only a starting point. To me, this is a bit like the toy train set that my son was obsessed with for a while. You first buy a very basic set that looks something like Figure 1.1. Figure 1.1: The toy version of base R. To take full advantage of R, you’ll want to add on packages. In the case of the train set, at this point, a doting grandparent adds on extensively through birthday presents, so you end up with something that looks like Figure 1.2. Figure 1.2: The toy version of what your R set-up will look like once you find cool packages to use for your research. The main source for installing packages for R remains the Comprehensive R Archive Network, or CRAN. However, GitHub is growing in popularity, especially for packages that are still in development. You can also create and share packages among your collaborators or co-workers, without ever posting them publicly. 1.2.2 Installing from CRAN The most popular place from which to get packages is currently CRAN. You can install packages from CRAN using R code. For example, telephone keypads include letters for each number (Figure 1.3), which allow companies to have “named” phone numbers that are easier for people to remember, like 1-800-GO-FEDEX and 1-800-FLOWERS. Figure 1.3: Telephone keypad with letters corresponding to each number. The phonenumber package is a cool little package that will convert between numbers and letters based on the telephone keypad. Since this package is on CRAN, you can install the package to your computer using the install.packages function: install.packages(&quot;phonenumber&quot;) This downloads the package from CRAN and saves it in a special location on your computer where R can load it when you’re ready to use it. 1.2.3 Loading an installed package Once you have installed a package, it will be saved to your computer, but you won’t be able to access it’s functions until you load it in your R session. You can load a package in an R session using the library function, with the package name inside the parentheses. library(phonenumber) One thing that people often find confusing when they start using R is knowing when to use and not use quotation marks. The general rule is that you use quotation marks when you want to refer to a character string literally, but no quotation marks when you want to refer to the value in a previously-defined object. For example, if you saved the string “Anderson” as the object my_name (my_name &lt;- “Anderson”), then in later code, if you type my_name (no quotation marks), you’ll get “Anderson”, while if you type out “my_name” (with quotation marks), you’ll get “my_name” (what you typed, literally). One thing that makes this rule confusing is that there are a few cases in R where you really should (by this rule) use quotation marks, but the function is coded to let you be lazy and get away without them. One example is the library function. In the above code, you want to literally load the package “phonenumber”, rather than load whatever character string is saved in the object named phonenumber. However, library is one of the functions where you can be lazy and skip the quotation marks, and it will still load “phonenumber” for you (although, if you want, this function also works if you follow the rule and call library(“phonenumber”) instead). Once a package is loaded, you can use all its exported (i.e., public) functions by calling them directly. For example, the phonenumber has a function called letterToNumber that converts a character string to a number. Once you’ve loaded phonenumber using library, you can use this function in your R session: fedex_number &lt;- &quot;GoFedEx&quot; letterToNumber(fedex_number) ## [1] &quot;4633339&quot; R vectors can have several different classes. One common class is the character class, which is the class of the character string we’re using here (“GoFedEx”). You’ll always put character strings in quotation marks. Another key class is numeric (numbers). Later in the course, we’ll introduce other classes that vectors can have, including factors and dates. 1.3 Basic code conventions of R 1.3.1 R’s MVP: The gets arrow The gets arrow, &lt;-, is R’s assignment operator. It takes whatever you’ve created on the right hand side of the &lt;- and saves it as an object with the name you put on the left hand side of the &lt;-. The basic structure of a call with a gets arrow looks like this: ## Note: Generic code [name of object] &lt;- [thing I want to save] Sometimes, we’ll show “generic” code in a code block, that doesn’t actually work if you put it in R, but instead shows the generic structure of an R call. We’ll try to always include a comment with any generic code, so you’ll know not to try to run it in R. For example, if I just type &quot;GoFedEx&quot; at the R prompt, R will print that string back to me, but won’t save it anywhere for me to use later: &quot;GoFedEx&quot; ## [1] &quot;GoFedEx&quot; However, if I assign &quot;GoFedEx&quot; to an object using a gets arrow, I can print it out or use it later by typing (“referencing”) that object name: fedex_number &lt;- &quot;GoFedEx&quot; fedex_number ## [1] &quot;GoFedEx&quot; letterToNumber(fedex_number) ## [1] &quot;4633339&quot; 1.3.2 Assignment operator wars: &lt;- vs. = You can make assignments in R using either the gets arrow (&lt;-) or =. When you read other people’s code, you’ll see both. R gurus advise using &lt;- rather than = when coding in R, and as you move to doing more complex things, some subtle problems might crop up if you use =. I have heard from someone in the know that you can tell the age of a programmer by whether he or she uses the gets arrow or =, with = more common among the young and hip. For this course, however, I am asking you to code according to Hadley Wickham’s R style guide, which specifies using the gets arrow for assignment. While you will be coding with the gets arrow exclusively in this course, it will be helpful for you to know that the two assignment arrows do pretty much the same thing: one_to_ten &lt;- 1:10 one_to_ten ## [1] 1 2 3 4 5 6 7 8 9 10 one_to_ten = 1:10 one_to_ten ## [1] 1 2 3 4 5 6 7 8 9 10 1.3.3 Naming objects When you assign objects, you will need to choose names for them. This object name is what you will type later in your code to reference the object and use it in functions, figures, etc. For example, with the following code, I am assigning the character string “GoFedEx” to an object that I am naming fedex_number: fedex_number &lt;- &quot;GoFedEx&quot; There are only two fixed rules for naming objects in R: Use only letters, numbers, and underscores Don’t start with anything but a letter In addition to these fixed rules, there are also some guidelines for naming objects that you should adopt now, since they will make your life easier as you advance to writing more complex code in R. The following three guidelines for naming objects are from Hadley Wickham’s R style guide: Use lower case for variable names (fedex_number, not FedExNumber) Use an underscore as a separator (fedex_number, not fedex.number or fedexNumber) Avoid using names that are already defined in R (e.g., don’t name an object mean, because a function named mean already exists) Another good practice is to name objects after nouns (e.g., fedex_number) and later, when you start writing functions, name those after verbs (e.g., call_fedex). You’ll want your object names to be short enough that they don’t take forever to type as you’re coding, but not so short that you can’t remember what they stand for. Sometimes, you’ll want to create an object that you won’t want to keep for very long. For example, you might want to create a small object to test some code, but you plan to not need the object again once you’ve done that. You may want to come up with some short, generic object names that you use for these kinds of objects, so that you’ll know that you can delete them without problems when you want to clean up your R session. There are all kinds of traditions for these placeholder variable names in computer science. foo and bar are two popular choices, as are, evidently, xyzzy, spam, ham, and norf. There are different placeholder names in different languages: for example, toto, truc, and azerty (French); and pippo, pluto, paperino (Disney character names; Italian). See the Wikipedia page on metasyntactic variables to find out more. 1.3.4 Commenting code Sometimes, you’ll want to include notes in your code. You can do this in all programming languages by using a comment character to start the line with your comment. In R, the comment character is the hash symbol, #. R will skip any line that starts with # in a script. For example, if you run the following code: # Don&#39;t print this. &quot;But print this&quot; ## [1] &quot;But print this&quot; R will only print the second, uncommented line. You can also use a comment in the middle of a line, to add a note on what you’re doing in that line of the code. R will skip any part of the code from the hash symbol on. For example: &quot;Print this&quot; ## But not this, it&#39;s a comment. ## [1] &quot;Print this&quot; 1.4 R’s most basic object types An R object stores some type of data that you want to use later in your R code, without fully recreating it. The content of R objects can vary from very simple (the &quot;GoFedEx&quot; string in the example code above) to very complex objects with lots of elements (for example, a machine learning model). There are a variety of different object types in R, shaped to fit different types of objects ranging from the simple to complex. In this section, we’ll start by describing two object types that you will use most often in basic data analysis, vectors (1-dimensional objects) and dataframes (2-dimensional objects). 1.4.1 Vectors To get an initial grasp of the vector object type in R, think of it as a 1-dimensional object, or a string of values. All values in a vector must be of the same class (i.e., all numbers, all characters, all dates). If you try to create a vector with elements from different classes (like “FedEx”, which is a character, and 3, a number), R will coerce all of the elements to the most generic class of any of the elements (i.e., “FedEx” and “3” will both become characters, since “3” can be changed to a character, but “FedEx” can’t be changed to a number). To create a vector from different elements, you’ll use the concatenation function, c to join them together, with commas between the elements. For example, to create a vector with the first five elements of the Fibonacci sequence, you can run: fibonacci &lt;- c(1, 1, 2, 3, 5) fibonacci ## [1] 1 1 2 3 5 Here is an example of creating a vector using elements with the character class instead of numbers (note the quotation marks used around each element for character strings): one_to_five &lt;- c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;, &quot;four&quot;, &quot;five&quot;) one_to_five ## [1] &quot;one&quot; &quot;two&quot; &quot;three&quot; &quot;four&quot; &quot;five&quot; If you mix classes when you create the vector, R will coerce all the elements to most generic of the elements’ classes: mixed_classes &lt;- c(1, 3, &quot;five&quot;) mixed_classes ## [1] &quot;1&quot; &quot;3&quot; &quot;five&quot; A vector’s length is the number of elements in the vector. You can use the length function to determine a vector’s length: length(mixed_classes) ## [1] 3 Once you create an object, you will often want to reference the whole object in future code. However, there will be some times when you’ll want to reference just certain elements of the object (for example, the first three values). You can pull out certain values from a vector by using indexing with square brackets ([...]) to identify the locations of the elements you want to pull, with a numeric vector inside the brackets that lists the numbered positions of the elements you want to get: fibonacci[2] # Get the second value ## [1] 1 fibonacci[c(1, 5)] # Get first and fifth values ## [1] 1 5 fibonacci[1:3] # Get the first three values ## [1] 1 1 2 You can also use logic to pull out some values of a vector. For example, you might only want to pull out even values from the fibonacci vector. We’ll cover using logical statements to index vectors later in the book. 1.4.2 Dataframes A dataframe is a 2-dimensional object, and is made of one or more vectors of the same length stuck together side-by-side. It is the closest R has to an Excel spreadsheet-type structure. You can create dataframes using the data.frame function. However, most often you will create a dataframe by reading in data from a file, using something like read.csv. To create a dataframe using data.frame, in this case by sticking together vectors you already have saved as R objects, you can run: fibonacci_seq &lt;- data.frame(num_in_seq = one_to_five, fibonacci_num = fibonacci) fibonacci_seq ## num_in_seq fibonacci_num ## 1 one 1 ## 2 two 1 ## 3 three 2 ## 4 four 3 ## 5 five 5 Note that this call requires that the one_to_five and fibonacci vectors are the same length, although they don’t have to be (and in this case aren’t) the same class of objects (one_to_five is a character class, fibonacci is numeric). You can also create a dataframe using data.frame even if you don’t have the vectors for the columns saved as objects. Instead, in this case, you can put the vector assignment directly within the data.frame call: fibonacci_seq &lt;- data.frame(num_in_seq = c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;, &quot;four&quot;, &quot;five&quot;), fibonacci_num = c(1, 1, 2, 3, 5)) fibonacci_seq ## num_in_seq fibonacci_num ## 1 one 1 ## 2 two 1 ## 3 three 2 ## 4 four 3 ## 5 five 5 You can put more than one function call in a single line of R code, as in this example (the c creates a vector, while the data.frame creates a dataframe, using the vectors created by the calls to c). When you use multiple functions within a single R call, R will evaluate starting from the inner-most parentheses out, much like the order of operations in a math equation with parentheses. The general format for using data.frame is: ## Note: Generic code [name of object] &lt;- data.frame([1st column name] = [1st column content], [2nd column name] = [2nd column content]) with an equals sign between the column name and column content for each column, and commas between each of the columns. You can use square-bracket indexing ([..., ...]) for dataframes, too, but now they’ll have two dimensions (rows, then columns). Put the rows you want before the comma, the columns after. If you want all of something (e.g., all rows in the dataframe), leave the designated spot blank. Here are two examples of using square-bracket indexing to pull a subset of the fibonacci_seq dataframe we created above: fibonacci_seq[1:2, 2] # First two rows, second column ## [1] 1 1 fibonacci_seq[5, ] # Last row, all columns ## num_in_seq fibonacci_num ## 5 five 5 If you forget to put the comma in the indexing for a dataframe (e.g., fibonacci_seq[1:2]), you will index out the columns that fall at that position or positions. To avoid confusion, I suggest that you always use indexing with a comma when working with dataframes. So far, we’ve only shown how to create dataframes from scratch within an R session. Usually, however, you’ll create R dataframes instead by reading in data from an outside file using read.csv and related functions. For example, you might want to analyze data on all the guests that came on the Daily Show, circa Jon Stewart. If you have this data in a comma-separated (csv) file on your computer called “daily_show_guests.csv”, you can read it into your R session with the following code: daily_show &lt;- read.csv(&quot;daily_show_guests.csv&quot;, header = TRUE, skip = 4) In this code, the read.csv function is reading in the data from “daily_show_guests”, while the gets arrow (&lt;-) assigns that data to the object daily_show, which you can then reference in later code to explore and plot the data. Once you’ve read in the data and saved the resulting dataframe as an object, you can use square-bracket indexing to look at the first two rows in the data: daily_show[1:2, ] ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## 1 1999 actor 1/11/99 Acting Michael J. Fox ## 2 1999 Comedian 1/12/99 Comedy Sandra Bernhard You can use the functions dim, nrow, and ncol to figure out the dimensions (number of rows and columns) of a dataframe: dim(daily_show) ## [1] 2693 5 nrow(daily_show) ## [1] 2693 ncol(daily_show) ## [1] 5 1.5 Using R functions 1.5.1 Function structure In general, functions in R take the following structure: ## Generic code function.name(parameter 1 = argument 1, parameter 2 = argument 2, parameter 3 = argument 3) The result of the function will be output to your R session, unless you choose to save the output in an object: ## Generic code new_object &lt;- function.name(parameter 1 = argument 1, parameter 2 = argument 2, parameter 3 = argument 3) Here are some example function calls, to give you examples of this structure: head(daily_show) ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## 1 1999 actor 1/11/99 Acting Michael J. Fox ## 2 1999 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 1999 television actress 1/13/99 Acting Tracey Ullman ## 4 1999 film actress 1/14/99 Acting Gillian Anderson ## 5 1999 actor 1/18/99 Acting David Alan Grier ## 6 1999 actor 1/19/99 Acting William Baldwin head(daily_show, n = 3) ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## 1 1999 actor 1/11/99 Acting Michael J. Fox ## 2 1999 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 1999 television actress 1/13/99 Acting Tracey Ullman daily_show &lt;- read.csv(&quot;daily_show_guests.csv&quot;, skip = 4, header = TRUE) Within the function call, parameters allow you to customize the function to run in a certain way (e.g., use a certain dataframe as an input, give output in a certain format). Some function parameters will have default arguments, which means that you don’t have to put a value for that parameter for the function to run, but you can if you want the function to do something other than the default. 1.5.2 Function help files You can find out more about a function, include what parameters it has and what the default values, if any, are by using ? before the function name in the R console. For example, to find out more about the read.csv command, run: ?read.csv From the “Usage” section of the help file, you can figure out that the only required parameter is file, the pathname of the file that you want to read in, since this is the only argument in the “Usage” example without an argument value: read.csv(file, header = TRUE, sep = &quot;,&quot;, quote = &quot;\\&quot;&quot;, dec = &quot;.&quot;, fill = TRUE, comment.char = &quot;&quot;, ...) You can also see from this “Usage” section that the default value of header is TRUE, the default value of sep is a comma, etc. The “Arguments” section explains each of the parameters, and possible arguments that each can take. For example, here is the explanation of the nrows parameter in the read.csv function: integer: the maximum number of rows to read in. Negative and other invalid values are ignored. From this, you can determine that you should put in a whole number, 1 or higher, and the function will only read in that many lines of the dataframe when you run read.csv. 1.5.3 Function parameters Each function parameter has a name (e.g., nrows, header, file). The safest way to call a function in R is to use the structure parameter name = argument value for every parameter, like this: head(x = daily_show, n = 3) However, you can also give argument values by position. For example, in the head function, the first parameter is x, the object you want to look at, and the second is n, the number of elements you want to include when you look at the object. If you know this, you can call head using the shorter call: head(daily_show, 3) If you use position alone, you will have problems if you don’t include arguments in exactly the right order. However, if you use parameter names to set each argument, it doesn’t matter what order you include arguments when calling a function: # These two calls return the exact same object head(x = daily_show, n = 3) head(n = 3, x = daily_show) Because code tends to be more robust to errors when you use parameter names to set arguments, we recommend against using position, rather than name, to give arguments when calling functions, at least while you’re learning R. It’s too easy to forget the exact order and get errors in your code. However, there is one exception– the first argument to a function is almost always required (i.e., there’s not a default value), and you very quickly learn what the first parameter of most functions are as soon as you start using the function regularly. Therefore, it’s fine to use position alone to specify the first argument in a function, but for now always use the parameter name to set any later arguments: head(daily_show, n = 3) Using the full parameter names for arguments can take a bit more time, since it requires more typing. However, RStudio helps you out with that by offering code completion. Once you start typing the first few letters of a parameter name within a function call, try pressing the tab key. All possible arguments that start with those letters should show up, and you can scroll through to pick the right one, or keep typing until the argument you want is atnthe top of the list of choices, and then press the tab key again. 1.6 In-course Exercise 1.6.1 About the dataset For today’s class, you’ll be using a dataset of all the guests on Jon Stewart’s The Daily Show. This data was originally collected by Nate Silver’s website, FiveThirtyEight and is available on FiveThirtyEight’s GitHub page under the Creative Commons Attribution 4.0 International License. The only change made to the original file was to add (commented) attribution information at the start of the file. First, check out a bit more about this data and its source: Check out the Creative Commons license. What are we allowed to do with this data? What restrictions are there on using the data? It’s often helpful to use prior knowledge to help check out or validate your dataset. One thing we might want to know about this data is if it covers the whole time that Jon Stewart hosted The Daily Show. Find out the dates he started and finished as host. Briefly browse around FiveThirtyEight’s GitHub data page. What are some other datasets available that you find interesting? You can scroll to the bottom of the page to get to the compiled README.md content, which gives the full titles and links to relevant datasets. You can also click on any dataset to get more information. Look at the GitHub page for this Daily Show data. How many columns will be in this dataset? What kind of information does the data include? In this exercise, you’re using data posted by FiveThirtyEight on GitHub. We’ll be using a lot of data that’s on GitHub this semester, and GitHub is being used behind-the-scenes for both this book and the course note slides. We’ll talk more about GitHub later, but you might find it interesting to explore a bit now. It’s a place where people can post, work on, and share code in a number of programming languages– it’s been referred to as “Facebook for Nerds”. You can search GitHub repositories and code specifically by programming language, so it can be a good way to find example R code from which to learn. If you have extra time: Check out the related article on FiveThirtyEight. What are some specific questions they used this data to answer for this article? Who is Nate Silver? 1.6.2 Getting the data onto your computer First, download the data from GitHub onto your computer. Make a directory (folder) on your computer specifically for this course (I strongly recommend that you put it somewhere where the file path will not have any spaces in it– for example, putting it in your home directory, under the name “R_Prog_Course” would be great. Putting it in a directory called “R Prog Course” would not.). Put the Daily Show data in your directory for this course. Take the following steps to get the data onto your computer If you do not yet have a directory (folder) just for this course, make one someplace straightforward like in your home directory. Do not use any spaces in the directory name. Download the file from GitHub. Right click on Raw and then choose “Download linked file”. Put the file into the directory you created for this course. Find out what your home directory is in R. To do this, make sure R is set to your home directory using setwd(&quot;~&quot;), and then get R to print that home directory path using getwd(). Outside of R, open Finder (or your system’s equivalent). Go to your home directory (mine, for example, is /Users/brookeanderson). Figure out how to get from your home directory to the directory you created for this course. For example, from my home directory, I would go RProgrammingForResearch to data. Go back into R. Set R’s working directory to your directory for this class using the setwd command, now that you know the pathname for the directory. For example, I would use setwd(&quot;~/RProgrammingForResearch/data&quot;). Use the list.files command to make sure that the “daily_show_guests.csv” file is in your current working directory. The full R code for this task might look something like: setwd(&quot;~&quot;) getwd() setwd(&quot;~/RProgrammingForResearch/data&quot;) getwd() list.files() &quot;daily_show_guests.csv&quot; %in% list.files() If you have extra time: See if you can figure out the last line of code in the example R code. 1.6.3 Getting the data into R Now that you have the dataset in your working directory, you can read it into R. This dataset is in a .csv (comma separated values) format. (We will talk more about different file formats next week.) You can read csv files into R using the read.csv function. Read the data into your R session Use the read.csv function to read the data into R and save it as the object daily_show. Use the help file for the read.csv function to figure out how this function works. To pull that up, use ?read.csv. Why are we using the option header = TRUE? Can you figure out why we’re using the skip option, and why it’s set to 4? Note that you need to put the file name in quotation marks. What would have happened if you’d used read.csv but hadn’t saved the result as the object daily_show? (For example, you’d run the code read.csv(&quot;daily_show_guests.csv&quot;) rather than daily_show &lt;- read.csv(&quot;daily_show_guests.csv&quot;).) Example R code: daily_show &lt;- read.csv(&quot;daily_show_guests.csv&quot;, header = TRUE, skip = 4) If you have extra time: Say this was a really big dataset. You want to check out just the first 10 rows to make sure that you’ve got your code right before you take the time to pull in the whole dataset. Use the help file for read.csv to figure out how to only read in a few rows. Look through the help file for other options available for read.csv. Can you think of examples when some of these options would be useful? Example R code: daily_show_first10 &lt;- read.csv(&quot;daily_show_guests.csv&quot;, header = TRUE, skip = 4, nrows = 10) daily_show_first10 1.6.4 Checking out the data You now have the data available in the daily_show option. You’ll want to check it out to make sure it read in correctly, and also to get a feel for the data. Throughout, you can use the help pages to figure out more about any of the functions being used (for example, ?dim). Take the following steps to check out the dataset Use indexing to look at the first two rows of the dataset. Based on this, what does each row “measure”? What information do you get for each “measurement”? As a reminder, indexing uses square brackets immediately after the object name. If the object has two dimensions, like a dataframe (rows and columns), you put the rows you want, then a comma, then the columns you want. If you want all rows (or columns), you leave that space blank. For example, if you wanted to get the first two rows and the first three columns, you’d use daily_show[1:2, 1:3]. If you wanted to get the first five rows and all the columns, you’d use daily_show[1:5, ]. Use the dim function to find out how many rows and columns this dataframe has. Based on what you found out about the data from the GitHub page, does it have the number of columns you expected? Based on what you know about the data (all the guests who came on The Daily Show with Jon Stewart), do you think it has about the right number of rows? Use the head function to look at the first few rows of the dataframe. Does it look like the rows go in order by date? What was the date of Jon Stewart’s first show? Does it look like this dataset covers that first show? Use the tail function to look at the last few rows of the dataframe. What is the last show date covered by the dataframe? Who was the last guest? Example R code: daily_show[1:2, ] dim(daily_show) head(daily_show) tail(daily_show) If you have extra time: Say you wanted to look at the first ten rows of the dataframe, rather than the first six. How could you use an option with head to do this? Example R code: head(daily_show, n = 10) 1.6.5 Using the data to answer questions Nate Silver was a guest on The Daily Show. Let’s use this data to figure out how many times he was a guest and when he was on the show. Find out more about Nate Silver on The Daily Show Use the subset function to create a new dataframe that only has the rows of daily_show when Nate Silve was a guest. Put it in the object nate_silver. Print out the full nate_silver dataframe by typing nate_silver. (You could just use this to answer both questions, but still try the next steps. They would be important with a bigger dataset.) To count the number of times Nate Silver was a guest, you’ll need to count the number of rows in the new dataset. You can either use the dim function or the nrow function to do this. What additional information does the dim function give you? To get the dates when Nate Silver was a guest, you can print out just the Show column of the dataframe. There are a few ways you can do this using indexing: nate_silver[ , 3] (since Show is the third column), nate_silver[ , &quot;Show&quot;], or nate_silver$Show. Try these. Example R code: nate_silver &lt;- subset(daily_show, Raw_Guest_List == &quot;Nate Silver&quot;) nate_silver dim(nate_silver) nrow(nate_silver) nate_silver[ , 3] nate_silver[ , &quot;Show&quot;] If you have extra time: When you print out the Show column, why does it also print out something underneath about Levels? Hint: This has to do with the class that R has saved this column as. What class is it currently? What other classes might we want to consider converting it to as we continue working with the dataset? Check out the example code below to get some ideas. Was Nate Silver the only statistician to be a guest on the show? What were the occupations that were only represented by one guest visit? Since GoogleKnowlege_Occupation is a factor, you can use the table function to create a new vector with the number of times each value of GoogleKnowlege_Occupation shows up. You can put this information into a new vector and then pull out only the values that equal 1 (so, only had one guest). (Note that “Statistician” doesn’t show up– there was only one person who was a guest, but he had three visits.) Pick your favorite “one-off” example and find out who the guest was for that occupation. Example R code: class(nate_silver$Show) range(nate_silver$Show) nate_silver$Show &lt;- as.Date(nate_silver$Show, format = &quot;%m/%d/%y&quot;) range(nate_silver$Show) diff(range(nate_silver$Show)) # Time between Nate&#39;s first and last shows statisticians &lt;- subset(daily_show, GoogleKnowlege_Occupation == &quot;Statistician&quot;) statisticians num_visits &lt;- table(daily_show[ , 2]) head(num_visits) # Note: This is a vector rather than a dataframe names(num_visits[num_visits == 1]) subset(daily_show, GoogleKnowlege_Occupation == &quot;chess player&quot;) subset(daily_show, GoogleKnowlege_Occupation == &quot;mathematician&quot;) subset(daily_show, GoogleKnowlege_Occupation == &quot;orca trainer&quot;) subset(daily_show, GoogleKnowlege_Occupation == &quot;Puzzle Creator&quot;) subset(daily_show, GoogleKnowlege_Occupation == &quot;Scholar&quot;) "],
["entering-and-cleaning-data-1.html", "Chapter 2 Entering and cleaning data #1 2.1 R scripts 2.2 Directories and pathnames 2.3 Diversion: paste 2.4 Reading data into R 2.5 Data cleaning 2.6 Dates in R 2.7 In-course Exercise", " Chapter 2 Entering and cleaning data #1 Download a pdf of the lecture slides covering this topic. There are four basic steps you will often repeat as you prepare to analyze data in R: Identify where the data is (If it’s on your computer, which directory? If it’s online, what’s the url?) Read data into R (read.csv, read.table) using the file path you figured out in step 1 Check to make sure the data came in correctly (dim, head, tail, str) Clean the data up In this chapter, I’ll go basics for each of these steps, as well as dive a bit deeper into some related topics you should learn now to make your life easier as you get started using R for research. 2.1 R scripts This is a good point in learning R for you to start putting your work in R scripts, rather than entering commands at the console. An R script is a plain text file where you can save a series of R commands. You can save the script and open it up later to see (or re-do) what you did earlier, just like you could with something like a Word document when you’re writing a paper. To open a new R script in RStudio, go to the menu bar and select “File” -&gt; “New File” -&gt; “R Script”. Alternatively, you can use the keyboard shortcut Command-Shift-N. Figure 2.1 gives an example of an R script file opened in RStudio and points out some interesting elements. Figure 2.1: Example of an R script in RStudio. To save a script you’re working on, you can click on the “Save” button (which looks like a floppy disk) at the top of your R script window in RStudio or use the keyboard shortcut Command-S. You should save R scripts using a “.R” file extension. Within the R script, you’ll usually want to type your code so there’s one command per line. If your command runs long, you can write a single call over multiple lines. It’s unusual to put more than one command on a single line of a script file, but you can if you separate the commands with semicolons (;). These rules all correspond to how you can enter commands at the console. Running R code from a script file is very easy in RStudio. You can use either the “Run” button or Command-Return, and any code that is selected (i.e., that you’ve highlighted with your cursor) will run at the console. You can use this functionality to run a single line of code, multiple lines of code, or even just part of a specific line of code. If no code is highlighted, then R will instead run all the code on the line with the cursor and then move the cursor down to the next line in the script. You can also run all of the code in a script. To do this, use the “Source” button at the top of the script window. You can also run the entire script either from the console or from within another script by using the source() function, with the filename of the script you want to run as the argument. For example, to run all of the code in a file named “MyFile.R” that is saved in your current working directory, run: source(&quot;MyFile.R&quot;) You can add comments into an R script to let others know (and remind yourself) what you’re doing and why. To do this, use R’s comment character, #. Any line on a script line that starts with # will not be read by R. You can also take advantage of commenting to comment out certain parts of code that you don’t want to run at the moment. While it’s generally best to write your R code in a script and run it from there rather than entering it interactively at the R console, there are some exceptions. A main example is when you’re initially checking out a dataset, to make sure you’ve read it in correctly. It often makes more sense to run commands for this task, like str(), head(), tail(), and summary(), at the console. These are all examples of commands where you’re trying to look at something about your data right now, rather than code that builds toward your analysis, or helps you read in or clean up your data. 2.2 Directories and pathnames 2.2.1 Directory structure It seems a bit of a pain and a bit complex to have to think about computer directory structure in the “basics” part of this class, but this structure is not terribly complex once you get the idea of it. There are a couple of very good reasons why it’s worth learning now. First, many of the most frustrating errors you get when you start using R trace back to understanding directories and filepaths. For example, when you try to read a file into R using only the filename, and that file is not in your current working directory, you will get an error like: Error in file(file, &quot;rt&quot;) : cannot open the connection In addition: Warning message: In file(file, &quot;rt&quot;) : cannot open file &#39;Ex.csv&#39;: No such file or directory This error is especially frustrating when you’re new to R because it happens at the very beginning of your analysis – you can’t even get your data in. Also, if you don’t understand a bit about working directories and how R looks for the file you’re asking it to find, you’d have no idea where to start to fix this error. Second, once you understand how to use pathnames, especially relative pathnames, to tell R how to find a file that is in a directory other than your working directory, you will be able to organize all of your files for a project in a much cleaner way. For example, you can create a directory for your project, then create one subdirectory to store all of your R scripts, and another to store all of your data, and so on. This can help you keep very complex projects more structured and easier to navigate. We’ll talk about these ideas more in the course sections on Reproducible Research, but it’s good to start learning how directory structures and filepaths work early. Your computer organizes files through a collection of directories. Chances are, you are fairly used to working with these in your daily life already (although you may call them “folders” rather than “directories”). For example, you’ve probably created new directories to store data files and Word documents for a specific project. Figure 2.2 illustrates the file directory structure on my computer. (Note that I have omitted many, many additional files and directories – this just shows an example of a few directories and files and how they are structured together). Directories are shown in blue, and files in green. Figure 2.2: An example of file directory structure. You can notice a few interesting things from Figure 2.2. First, you might notice the structure includes a few of the directories that you use a lot on your own computer, like Desktop, Documents, and Downloads. Next, the directory at the very top is the computer’s root directory, /. For a PC, the root directory might something like C:; for Unix and Macs, it’s usually /. Finally, if you look closely, you’ll notice that it’s possible to have different files in different locations of the directory structure with the same file name. For example, in the figure, there are files names heat_mort.csv in both the CourseText directory and in the example_data directory. These are two different files with different contents, but they can have the same name as long as they’re in different directories. This fact – that you can have files with the same name in different places – should help you appreciate how useful it is that R requires you to give very clear directions to describe exactly which file you want R to read in, if you aren’t reading in something in your current working directory. You will have a home directory somewhere near the top of your structure, although it’s likely not your root directory. My home directory is /Users/brookeanderson. I’ll describe just a bit later how you can figure out what your own home directory is on your own computer. 2.2.2 Working directory When you run R, it’s always running from within some working directory, which will be one of the directories somewhere in your computer’s directory structure. At any time, you can figure out which directory R is working in by running the command getwd() (short for “get working directory”). For example, my R session is currently running in the following directory: getwd() ## [1] &quot;/home/travis/build/geanders/RProgrammingForResearch&quot; This means that, for my current R session, R is working in the RProgrammingForResearch subdirectory of my brookeanderson directory (which is my home directory). There are a few general rules for which working directory R will start in when you open an R session. These are not absolute rules, but they’re generally true. If you have R closed, and you open it by double-clicking on an R script, then R will generally open with, as its working directory, the directory in which that script is stored. This is often a very convenient convention, because often any of the data you’ll be reading in for that script is somewhere near where the script file is saved in the directory structure. If you open R by double-clicking on the R icon in “Applications” (or something similar on a PC), R will start in its default working directory. You can find out what this is, or change it, in RStudio’s “Preferences”. I have never had a compelling reason to change this on my own computer, as I find it very easy to just move around the directories and set a new working directory using pathnames and the setwd() function. Finally, later in the course, we’ll talk about using R Projects from within RStudio. If you open an R Project, R will start in that project’s working dirctory (the directory in which the .Rproj file for the project is stored). 2.2.3 File and directory pathnames Once you get a picture of how your directories and files are organized, you can use pathnames, either absolute or relative, to move around the directories, set a different working directory, and read in files from different directories than your current working directory. Pathnames are the directions for getting to a directory or file stored on your computer. When you want to reference a directory or file, you can use one of two types of pathnames: Relative pathname: How to get to the file or directory from your current working directory Absolute pathname: How to get to the file or directory from anywhere on the computer Absolute pathnames are a bit more straightforward conceptually, because they don’t depend on your current working directory. However, they’re also a lot longer to write, and they’re much less convenient if you’ll be sharing some of your code with other people who might run it on their own computers. I’ll explain this second point a bit more later in this section. Absolute pathnames give the full directions to a directory or file, starting all the way at the root directory. For example, the heat_mort.csv file in the CourseText directory has the absolute pathname: &quot;/Users/brookeanderson/Desktop/RCourseFall2015/CourseText/heat_mort.csv&quot; You can use this absolute pathname to read this file in using read.csv. This absolute pathname will always work, regardless of your current working directory, because it gives directions from the root – it will always be clear to R exactly what file you’re talking about. Here’s the code to use to read that file in using the read.csv function with the file’s absolute pathname: heat_mort &lt;- read.csv(&quot;/Users/brookeanderson/Desktop/RCourseFall2015/CourseText/heat_mort.csv&quot;) The relative pathname, on the other hand, gives R the directions for how to get to a directory or file from the current working directory. If the file or directory you’re looking for is pretty close to your current working directory in your directory structure, then a relative pathname can be a much shorter way to tell R how to get to the file than an absolute pathname. However, the relative pathname depends on your current working directory – the relative pathname that works perfectly when you’re working in one directory will not work at all once you move into a different working directory. As an example of a relative pathname, say you’re working in the directory RCourseFall2015 within the file structure shown in Figure 2.2, and you want to read in the heat_mort.csv file in the CourseText directory. To get from RCourseFall2015 to that file, you’d need to look in the subdirectory CourseText, where you could find heat_mort.csv. Therefore, the relative pathname from your working directory would be: &quot;CourseText/heat_mort.csv&quot; You can use this relative pathname to tell R where to find and read in the file: heat_mort &lt;- read.csv(&quot;CourseText/heat_mort.csv&quot;) While this pathname is much shorter than the absolute pathname, it is important to remember that if you changed your working directory (for example, if you used setwd(&quot;CourseText&quot;) to move into the CourseText directory), this relative pathname would no longer work. There are a few abbreviations that can be really useful for pathnames: Shorthand Meaning ~ Home directory . Current working directory .. One directory up from current working directory ../.. Two directories up from current working directory These can help you keep pathnames shorter and also help you move “up-and-over” to get to a file or directory that’s not on the direct path below your current working directory. For example, my home directory is /Users/brookeanderson. If I wanted to change my working directory to the Downloads directory, which is a direct sub-directory of my home directory, I could use: setwd(&quot;~/Downloads&quot;) As a second example, say I was working in the working directory CourseText, but I wanted to read in the heat_mort.csv file that’s in the example_data directory, rather than the one in the CourseText directory. I can use the .. abbreviation to tell R to look up one directory from the current working directory, and then down within a subdirectory of that. The relative pathname in this case is: &quot;../Week2_Aug31/example_data/heat_mort.csv&quot; This tells R to look one directory up from the working directory (..), which in this case is to RCourseFall2015, and then down within that directory to Week2_Aug31, then to example_data, and then to look there for the file heat_mort.csv. The relative pathname to read this file while R is working in the CourseTest directory would be: heat_mort &lt;- read.csv(&quot;../Week2_Aug31/example_data/heat_mort.csv&quot;) These relative pathnames would “break” as soon as you tried them from a different working directory – this fact might make it seem like you would never want to use relative pathnames, and would always want to use absolute ones instead, even if they’re longer. If that were the only consideration (length of the pathname), then perhaps that would be true. However, as you do more and more in R, there will likely be many occasions when you want to use relative pathnames instead. They are particularly useful if you ever want to share a whole directory, with R scripts and data, with a collaborator. In that case, if you’ve used relative pathnames, all the code should work fine for the person you share with, even though they’re running it on their own computer. Conversely, if you’d used absolute pathnames, none of them would work on another computer, because the “top” of the directory structure (i.e., for me, /Users/brookeanderson/Desktop) will almost definitely be different for your collaborator’s computer than it is for yours. You can use absolute or relative pathnames for a number of things: To set your working directory: setwd(&quot;../Week2_Aug31&quot;), for example To read in files from a different directory (as shown in the previous examples) To list files in a different directory: for example, list.files(&quot;..&quot;) will list all files in the directory directly about your current working directory (the parent directory of your working directory) If you’re getting errors reading in files, and you think it’s related to the relative pathname you’re using, it’s often helpful to use list.files() to make sure the file you’re trying to load is in the directory that the relative pathname you’re using is directing R to. 2.3 Diversion: paste This is a good opportunity to explain how to use some functions that can be very helpful when you’re using relative or absolute pathnames: paste() and paste0(). As a bit of important background information, it’s important that you understand that you can save a pathname (absolute or relative) as an R object, and then use that R object in calls to later functions like list.files() and read.csv(). For example, to use the absolute pathname to read the heat_mort.csv file in the CourseText directory, you could run: my_file &lt;- &quot;/Users/brookeanderson/Desktop/RCourseFall2015/CourseText/heat_mort.csv&quot; heat_mort &lt;- read.csv(my_file) You’ll notice from this code that the pathname to get to a directory or file can sometimes become ungainly and long. To keep your code cleaner, you can address this by using the paste or paste0 functions. These functions come in handy in a lot of other applications, too, but this is a good place to introduce them. The paste() function is very straightforward. It takes, as inputs, a series of different character strings you want to join together, and it pastes them together in a single character string. (As a note, this means that your result vector will only be one element long, for basic uses of paste(), while the inputs will be several different character stings.) You separate all the different things you want to paste together using with commas in the function call. For example: paste(&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;) ## [1] &quot;Sunday Monday Tuesday&quot; length(c(&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;)) ## [1] 3 length(paste(&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;)) ## [1] 1 The paste() function has an option called sep =. This tells R what you want to use to separate the values you’re pasting together in the output. The default is for R to use a space, as shown in the example above. To change the separator, you can change this option, and you can put in just about anything you want. For example, if you wanted to paste all the values together without spaces, you could use sep = &quot;&quot;: paste(&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, sep = &quot;&quot;) ## [1] &quot;SundayMondayTuesday&quot; As a shortcut, instead of using the sep = &quot;&quot; option, you could achieve the same thing using the paste0 function. This function is almost exacly like paste, but it defaults to &quot;&quot; (i.e., no space) as the separator between values by default: paste0(&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;) ## [1] &quot;SundayMondayTuesday&quot; With pathnames, you will usually not want spaces. Therefore, you could think about using paste0() to write an object with the pathname you want to ultimately use in commands like list.files() and setwd(). This will allow you to keep your code cleaner, since you can now divide long pathnames over multiple lines: my_file &lt;- paste0(&quot;/Users/brookeanderson/Desktop/&quot;, &quot;RCourseFall2015/CourseText/heat_mort.csv&quot;) heat_mort &lt;- read.csv(my_file) You will end up using paste() and paste0() for many other applications, but this is a good example of how you can start using these functions to start to get a feel for them. 2.4 Reading data into R Data comes in files of all shapes and sizes. R has the capability to read data in from many of these, even priorietary files for other software (e.g., Excel and SAS files). As a small sample, here are some of the types of data files that R can read and work with: Flat files (much more about these in just a minute) Files from other statistical packages (SAS, Excel, Stata, SPSS) Tables on webpages (e.g., the table on ebola outbreaks near the end of this Wikipedia page) Data in a database (e.g., MySQL, Oracle) Data in JSON and XML formats Really crazy data formats used in other disciplines (e.g., netCDF files from climate research, MRI data stored in Analyze, NIfTI, and DICOM formats) Geographic shapefiles Data through APIs Often, it is possible to read in and clean up even incredibly messy data, by using functions like scan and readLines to read the data in a line at a time, and then using regular expressions (which I’ll cover in the “Intermediate” section of the course) to clean up each line as it comes in. In over a decade of coding in R, I think the only time I’ve come across a data file I couldn’t get into R was for proprietary precision agriculture data collected at harvest by a combine. 2.4.1 Reading local flat files Much of the data that you will want to read in will be in flat files. Basically, these are files that you can open using a text editor; the most common type you’ll work with are probably comma-separated files (often with a .csv or .txt file extension). Most flat files come in two general categories: Fixed width files Delimited files “.csv”: Comma-separated values “.tab”, “.tsv”: Tab-separated values Other possible delimiters: colon, semicolon, pipe (“|”) Fixed width files are files where a column always has the same width, for all the rows in the column. These tend to look very neat and easy-to-read when you open them in a text editor. For example, the first few rows of a fixed-width file might look like this: Course Number Day Time Intro to Epi 501 M/W/F 9:00-9:50 Advanced Epi 521 T/Th 1:00-2:15 Delimited files use some delimiter (for example, a column or a tab) to separate each column value within a row. The first few rows of a delimited file might look like this: Course, Number, Day, Time &quot;Intro to Epi&quot;, 501, &quot;M/W/F&quot;, &quot;9:00-9:50&quot; &quot;Advanced Epi&quot;, 521, &quot;T/Th&quot;, &quot;1:00-2:15&quot; These flat files can have a number of different file extensions. The most generic is .txt, but they will also have ones more specific to their format, like .csv for a comma-delimited file or .fwf for a fixed with file. R can read in data from both fixed with and delimited flat files. The only catch is that you need to tell R a bit more about the format of the flat file, including whether it is fixed width or delimited. If the file is fixed width, you will usually have to tell R the width of each column. If the file is delimited, you’ll need to tell R which delimiter is being used. If the file is delimited, you can use the read.table family of functions to read it in. This family of functions includes several specialized functions. All members of the read.table family are doing the same basic thing. The only difference is what defaults each function has for the separator (sep) and the decimal point (dec). Members of the read.table family include: Function Separator Decimial point read.table comma period read.csv comma period read.csv2 semi-colon comma read.delim tab period read.delim2 tab period You can use read.table to read in any delimited file, regardless of the separator and the value used for the decimal point. However, you will need to specify these values using the sep and dec parameters if they differ from the defaults for read.table (a space for the delimiter and period for the decimal). If you remember the more specialized function call, therefore, you can save yourself some typing. There are a few other default values besides sep and dec that differ between different functions in this family: header, for example, specifies whether the first row should be used as column names. For example, to read in the Ebola data, which is comma-delimited, you could either use read.table with a sep argument specified or use read.csv, in which case you don’t have to specify sep: # These two calls do the same thing ebola &lt;- read.table(&quot;data/country_timeseries.csv&quot;, sep = &quot;,&quot;, header = TRUE) ebola &lt;- read.csv(&quot;data/country_timeseries.csv&quot;) These functions have a number of different parameters to help you tell R how to read in data. For example, if the first few lines of the file aren’t part of the tabular data, you can tell R how many rows of the file to skip before it starts reading in the data. If the data uses an unusual value for missing data (e.g., -999), you can specify that, as well. Some of the interesting parameters with the read.table family of functions are: Option Description sep What is the delimiter in the data? skip How many lines of the start of the file should you skip? header Does the first line you read give column names? as.is Should you bring in strings as characters, not factors? nrows How many rows do you want to read in? na.strings How are missing values coded? Remember that you can always find out more about a function by looking at its help file. For example, check out ?read.table and ?read.fwf. You can also use the help files to determine the default values of arguments for each function. 2.4.2 The read_* functions The read.table family of functions are part of base R. There is a newer package called readr that has a family of read_* functions. These functions are very similar, but have some more sensible defaults. Compared to the read.table family of functions, the read_* functions: Work better with large datasets: faster, includes progress bar Have more sensible defaults (e.g., characters default to characters, not factors) Functions in the read_* family include: read_csv, read_tsv (specific delimiters) read_delim, read_table (generic) read_fwf read_log read_lines These functions work very similarly to functions from the read.table family. For example, to read in the Daily Show guest data, you can call: library(readr) daily_show &lt;- read_csv(&quot;data/daily_show_guests.csv&quot;, skip = 4) ## Parsed with column specification: ## cols( ## YEAR = col_integer(), ## GoogleKnowlege_Occupation = col_character(), ## Show = col_character(), ## Group = col_character(), ## Raw_Guest_List = col_character() ## ) The message that R prints after this call (“Parsed with column specification:..”) lets you know what classes R used for each column (this function tries to guess the appropriate function and, unlike the readr functions, will assign characters to a character rather than factor class – this is usually what you want). The readr package is a member of the tidyverse of packages. The tidyverse describes an evolving collection of R packages with a common philosophy, and they are unquestionably changing the way people code in R. Most were developed in part or full by Hadley Wickham and others at RStudio. Many of these packages are only a few years old, but have been rapidly adapted by the R community. As a result, newer examples of R code will often look very different from the code in older R scripts, including examples in books that are more than a few years old. In this course, I’ll focus on “tidyverse” functions when possible, but I do put in details about base R equivalent functions or processes at some points – this will help you interpret older code. You can use the tidyverse package to download all tidyverse packages at one. 2.4.3 Reading online flat files So far, I’ve only shown you how to read in data from files that are saved to your computer. R can also read in data directly from the web. If a flat file is posted online, you can read it into R in almost exactly the same way that you would read in a local file. The only difference is that you will use the file’s url instead of a local file path for the file argument. With the read_* family of functions, you can do this both for flat files from a non-secure webpage (i.e., one that starts with http) and for files from a secure webpage (i.e., one that starts with https), including GitHub and Dropbox. With the read.table family of functions, you can read in online flat files from non-secure webpages, but not from secure ones. For example, to read in the tab-separated file saved at this web address, which is non-secure, you can run: url &lt;- paste0(&quot;http://www2.unil.ch/comparativegenometrics&quot;, &quot;/docs/NC_006368.txt&quot;) ld_genetics &lt;- read_tsv(url) ld_genetics[1:5, 1:4] ## # A tibble: 5 × 4 ## pos nA nC nG ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 500 307 153 192 ## 2 1500 310 169 207 ## 3 2500 319 167 177 ## 4 3500 373 164 168 ## 5 4500 330 175 224 Similarly , to read in data from this GitHub repository of Ebola data, which is a secure website, you can run: url &lt;- paste0(&quot;https://raw.githubusercontent.com/cmrivers/&quot;, &quot;ebola/master/country_timeseries.csv&quot;) ebola &lt;- read_csv(url) ebola[1:3, 1:3] ## # A tibble: 3 × 3 ## Date Day Cases_Guinea ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 1/5/2015 289 2776 ## 2 1/4/2015 288 2775 ## 3 1/3/2015 287 2769 2.4.4 Saving and loading R objects You can save an R object you’ve created as an .RData file. To save an R object in a .RData file, use the save function: save(ebola, file = &quot;Ebola.RData&quot;) list.files() ## [1] &quot;_book&quot; &quot;_bookdown.yml&quot; ## [3] &quot;_build.sh&quot; &quot;_deploy.sh&quot; ## [5] &quot;_output.yml&quot; &quot;01-course_info.Rmd&quot; ## [7] &quot;02-prelim.Rmd&quot; &quot;03-databasics.Rmd&quot; ## [9] &quot;book.bib&quot; &quot;data&quot; ## [11] &quot;DESCRIPTION&quot; &quot;Ebola.RData&quot; ## [13] &quot;figures&quot; &quot;homework.Rmd&quot; ## [15] &quot;index.Rmd&quot; &quot;LICENSE&quot; ## [17] &quot;packages.bib&quot; &quot;preamble.tex&quot; ## [19] &quot;README.md&quot; &quot;references.Rmd&quot; ## [21] &quot;RProgrammingForResearch.Rmd&quot; &quot;RProgrammingForResearch.Rproj&quot; ## [23] &quot;slides&quot; &quot;style.css&quot; ## [25] &quot;toc.css&quot; &quot;vocabulary.Rmd&quot; Notice that, once you save the object, a new file named “Ebola.RData” is listed in the files in your current working directory. The default is for R to save the R object in your current working directory; to save it elsewhere, use a full relative or absolute pathname for the file argument. Once you’ve saved an R object, you can re-load it later using the load function with the object’s file path. For example, since I’ve saved this R object, I can remove it from my current R workspace using the rm function, after which it will not show up when I run ls: rm(ebola) ls() ## [1] &quot;ld_genetics&quot; &quot;my_dir&quot; &quot;url&quot; Then I can use the load command to re-load the object, after which it will again show up as an object in my R workspace: load(&quot;Ebola.RData&quot;) ls() ## [1] &quot;ebola&quot; &quot;ld_genetics&quot; &quot;my_dir&quot; &quot;url&quot; There is one caveat for saving R objects: some people suggest you avoid this if possible, to make your research more reproducible. Imagine someone wants to look at your data and code in 30 years. R might not work the same way, so you might not be able to read an .RData file. Notice that, if you try to open an .RData file in a text edit, it won’t make any sense. However, you can open flat files (e.g., .csv, .txt) and R scripts (.R) in text editors – you should still be able to do this regardless of what happens to R. Some potential exceptions, when it might be useful to save an R object, include when: You have an object that you need to save that has a structure that won’t work well in a flat file (a list rather than a dataframe, for example); or Your starting dataset is very large, and it would take a long time for you to read in your data fresh every time. In this case it may make sense to do some data cleaning and then save the cleaned R object as a .RData file, but be sure to also save the script you used to clean the raw data. 2.4.5 Reading other file types Later in the course, we’ll talk about how to open a variety of other file types in R. However, you might find it immediately useful to be able to read in files from other statistical programs. There are two “tidyverse” packages – readxl and haven – that help with this. They allow you to read in files from the following formats: File type Function Package Excel read_excel readxl SAS read_sas haven SPSS read_spss haven Stata `read_stata haven 2.5 Data cleaning Once you have loaded data into R, you’ll likely need to clean it up a little before you’re ready to analyze it. Here, I’ll go over the first steps of how to do that with functions from dplyr, another package in the tidyverse. Here are some of the most common data-cleaning tasks, along with the corresponding dplyr function for each: Task dplyr function Renaming columns rename Filtering to certain rows filter Selecting certain columns select Adding or changing columns mutate In this section, I’ll describe how to do each of these four tasks; in later sections of the course, we’ll go much deeper into how to clean messier data. For the examples in this section, I’ll use example data listing guests to the Daily Show. To follow along with these examples, you’ll want to load that data, as well as load the dplyr package (install it using install.packages if you have not already): library(dplyr) daily_show &lt;- read_csv(&quot;data/daily_show_guests.csv&quot;, skip = 4) I’ve used this data in previous examples, but as a reminder, here’s what it looks like: head(daily_show) ## # A tibble: 6 × 5 ## YEAR GoogleKnowlege_Occupation Show Group Raw_Guest_List ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1999 actor 1/11/99 Acting Michael J. Fox ## 2 1999 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 1999 television actress 1/13/99 Acting Tracey Ullman ## 4 1999 film actress 1/14/99 Acting Gillian Anderson ## 5 1999 actor 1/18/99 Acting David Alan Grier ## 6 1999 actor 1/19/99 Acting William Baldwin 2.5.1 Renaming columns A first step is often re-naming the columns of the dataframe. It can be hard to work with a column name that: is long includes spaces includes upper case You can check out the column names for a dataframe using the colnames function, with the dataframe object as the argument. Several of the column names in daily_show have some of these issues: colnames(daily_show) ## [1] &quot;YEAR&quot; &quot;GoogleKnowlege_Occupation&quot; ## [3] &quot;Show&quot; &quot;Group&quot; ## [5] &quot;Raw_Guest_List&quot; To rename these columns, use rename. The basic syntax is: ## Generic code rename(dataframe, new_column_name_1 = old_column_name_1, new_column_name_2 = old_column_name_2) The first argument is the dataframe for which you’d like to rename columns. Then you list each pair of new versus old column names (in that order) for each of the columns you want to rename. To rename columns in the daily_show data using rename, for example, you would run: daily_show &lt;- rename(daily_show, year = YEAR, job = GoogleKnowlege_Occupation, date = Show, category = Group, guest_name = Raw_Guest_List) head(daily_show, 3) ## # A tibble: 3 × 5 ## year job date category guest_name ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1999 actor 1/11/99 Acting Michael J. Fox ## 2 1999 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 1999 television actress 1/13/99 Acting Tracey Ullman Many of the functions in tidyverse packages, including those in dplyr, provide exceptions to the general rule about when to use quotation marks versus when to leave them off. Unfortunately, this may make it a bit hard to learn when to use quotation marks versus when not to. One way to think about this, which is a bit of an oversimplification but can help as you’re learning, is to assume that anytime you’re using a dplyr function, every column in the dataframe you’re working with has been loaded to your R session as its own object. 2.5.2 Selecting columns Next, you may want to select only some columns of the dataframe. You can use the select function from dplyr to subset the dataframe to certain columns. The basic structure of this command is: ## Generic code select(dataframe, column_name_1, column_name_2, ...) In this call, you first specify the dataframe to use and then list all of the column names to include in the output dataframe, with commas between each column name. For example, to select all columns in daily_show except year (since that information is already included in date), run: select(daily_show, job, date, category, guest_name) ## # A tibble: 2,693 × 4 ## job date category guest_name ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 actor 1/11/99 Acting Michael J. Fox ## 2 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 television actress 1/13/99 Acting Tracey Ullman ## 4 film actress 1/14/99 Acting Gillian Anderson ## 5 actor 1/18/99 Acting David Alan Grier ## 6 actor 1/19/99 Acting William Baldwin ## 7 Singer-lyricist 1/20/99 Musician Michael Stipe ## 8 model 1/21/99 Media Carmen Electra ## 9 actor 1/25/99 Acting Matthew Lillard ## 10 stand-up comedian 1/26/99 Comedy David Cross ## # ... with 2,683 more rows Don’t forget that, if you want to change column names in the saved object, you must reassign the object to be the output of rename. If you run one of these cleaning functions without reassigning the object, R will print out the result, but the object itself won’t change. You can take advantage of this, as I’ve done in this example, to look at the result of applying a function to a dataframe without changing the original dataframe. This can be helpful as you’re figuring out how to write your code. The select function also provides some time-saving tools. For example, in the last example, we wanted all the columns except one. Instead of writing out all the columns we want, we can use - with the columns we don’t want to save time: daily_show &lt;- select(daily_show, -year) head(daily_show, 3) ## # A tibble: 3 × 4 ## job date category guest_name ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 actor 1/11/99 Acting Michael J. Fox ## 2 Comedian 1/12/99 Comedy Sandra Bernhard ## 3 television actress 1/13/99 Acting Tracey Ullman 2.5.3 Filtering to certain rows Next, you might want to filter the dataset down so that it only includes certain rows. For example, you might want to get a dataset with only the guests from 2015, or only guests who are scientists. You can use the filter function from dplyr to filter a dataframe down to a subset of rows. The syntax is: ## Generic code filter(dataframe, logical statement) The logical statement in this call gives the condition that a row must meet to be included in the output data frame. For example, if you want to create a data frame that only includes guests who were scientists, you can run: scientists &lt;- filter(daily_show, category == &quot;Science&quot;) head(scientists) ## # A tibble: 6 × 4 ## job date category guest_name ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 neurosurgeon 4/28/03 Science Dr Sanjay Gupta ## 2 scientist 1/13/04 Science Catherine Weitz ## 3 physician 6/15/04 Science Hassan Ibrahim ## 4 doctor 9/6/05 Science Dr. Marc Siegel ## 5 astronaut 2/13/06 Science Astronaut Mike Mullane ## 6 Astrophysicist 1/30/07 Science Neil deGrasse Tyson To build a logical statment to use in filter, you’ll need to know some of R’s logical operators. Some of the most commonly used ones are: Operator Meaning Example == equals category == &quot;Acting&quot; != does not equal category != &quot;Comedy %in% is in category %in% c(&quot;Academic&quot;, &quot;Science&quot;) is.na() is NA is.na(job) !is.na() is not NA !is.na(job) &amp; and year == 2015 &amp; category == &quot;Academic&quot; | or year == 2015 | category == &quot;Academic&quot; We’ll use these logical operators a lot more as the course continues, so they’re worth learning by heart. Two common errors with logical operators are: (1) Using = instead of == to check if two values are equal; and (2) Using == NA instead of is.na to check for missing observations. 2.5.4 Add or change columns You can change a column or add a new column using the mutate function from the dplyr package. That function has the syntax: # Generic code mutate(dataframe, changed_column = function(changed_column), new_column = function(other arguments)) For example, the job column in daily_show sometimes uses upper case and sometimes does not (this call uses the unique function to list only unique values in this column): head(unique(daily_show$job), 10) ## [1] &quot;actor&quot; &quot;Comedian&quot; &quot;television actress&quot; ## [4] &quot;film actress&quot; &quot;Singer-lyricist&quot; &quot;model&quot; ## [7] &quot;stand-up comedian&quot; &quot;actress&quot; &quot;comedian&quot; ## [10] &quot;Singer-songwriter&quot; To make all the observations in the job column lowercase, use the tolower function within a mutate function: mutate(daily_show, job = tolower(job)) ## # A tibble: 2,693 × 4 ## job date category guest_name ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 actor 1/11/99 Acting Michael J. Fox ## 2 comedian 1/12/99 Comedy Sandra Bernhard ## 3 television actress 1/13/99 Acting Tracey Ullman ## 4 film actress 1/14/99 Acting Gillian Anderson ## 5 actor 1/18/99 Acting David Alan Grier ## 6 actor 1/19/99 Acting William Baldwin ## 7 singer-lyricist 1/20/99 Musician Michael Stipe ## 8 model 1/21/99 Media Carmen Electra ## 9 actor 1/25/99 Acting Matthew Lillard ## 10 stand-up comedian 1/26/99 Comedy David Cross ## # ... with 2,683 more rows 2.5.5 Piping So far, I’ve shown how to use these dplyr functions one at a time to clean up the data, reassigning the dataframe object at each step. However, there’s a trick called “piping” that will let you clean up your code a bit when you’re writing a script to clean data. If you look at the format of these dplyr functions, you’ll notice that they all take a dataframe as their first argument: # Generic code rename(dataframe, new_column_name_1 = old_column_name_1, new_column_name_2 = old_column_name_2) select(dataframe, column_name_1, column_name_2) filter(dataframe, logical statement) mutate(dataframe, changed_column = function(changed_column), new_column = function(other arguments)) Without piping, you have to reassign the dataframe object at each step of this cleaning if you want the changes saved in the object: daily_show &lt;-read_csv(&quot;data/daily_show_guests.csv&quot;, skip = 4) daily_show &lt;- rename(daily_show, job = GoogleKnowlege_Occupation, date = Show, category = Group, guest_name = Raw_Guest_List) daily_show &lt;- select(daily_show, -YEAR) daily_show &lt;- mutate(daily_show, job = tolower(job)) daily_show &lt;- filter(daily_show, category == &quot;Science&quot;) Piping lets you clean this code up a bit. It can be used with any function that inputs a dataframe as its first argument. It pipes the dataframe created right before the pipe (%&gt;%) into the function right after the pipe. With piping, therefore, the same data cleaning looks like: daily_show &lt;-read_csv(&quot;data/daily_show_guests.csv&quot;, skip = 4) %&gt;% rename(job = GoogleKnowlege_Occupation, date = Show, category = Group, guest_name = Raw_Guest_List) %&gt;% select(-YEAR) %&gt;% mutate(job = tolower(job)) %&gt;% filter(category == &quot;Science&quot;) Notice that, when piping, the first argument (the name of the dataframe) is excluded from all function calls that follow a pipe. This is because piping sends the dataframe from the last step into each of these functions as the dataframe argument. 2.5.6 Base R equivalents to dplyr functions Just so you know, all of these dplyr functions have alternatives, either functions or processes, in base R: dplyr Base R equivalent rename Reassign colnames select Square bracket indexing filter subset mutate Use $ to change / create columns You will see these alternatives used in older code examples. 2.6 Dates in R As part of the data cleaning process, you may want to change the class of some of the columns in the dataframe. For example, you may want to change a column from a character to a date. Here are some of the most common vector classes in R: Class Example character “Chemistry”, “Physics”, “Mathematics” numeric 10, 20, 30, 40 factor Male [underlying number: 1], Female [2] Date “2010-01-01” [underlying number: 14,610] logical TRUE, FALSE To find out the class of a vector (including a column in a dataframe – remember each column can be thought of as a vector), you can use class(): class(daily_show$date) ## [1] &quot;character&quot; It is especially common to need to convert dates during the data cleaning process, since date columns will usually be read into R as characters or factors – you can do some interesting things with vectors that are in a Date class that you cannot do with a vector in a character class. To convert a vector to the Date class, you can use the as.Date function. For example, to convert the date column in the daily_show data into a Date class, you can run: daily_show &lt;- mutate(daily_show, date = as.Date(date, format = &quot;%m/%d/%y&quot;)) head(daily_show, 3) ## # A tibble: 3 × 4 ## job date category guest_name ## &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; ## 1 neurosurgeon 2003-04-28 Science Dr Sanjay Gupta ## 2 scientist 2004-01-13 Science Catherine Weitz ## 3 physician 2004-06-15 Science Hassan Ibrahim class(daily_show$date) ## [1] &quot;Date&quot; Once you have an object in the Date class, you can do things like plot by date, calculate the range of dates, and calculate the total number of days the dataset covers: range(daily_show$date) diff(range(daily_show$date)) You can convert dates expressed in a number of different ways into a Date class in R, as long as you can explain to R how to parse the format that the date is in before you convert it. The only tricky thing in converting objects into a Date class is learning the abbreviations for the format option of the as.Date function. Here are some common ones: Abbreviation Meaning %m Month as a number (e.g., 1, 05) %B Full month name (e.g., August) %b Abbreviated month name (e.g., Aug) %y Two-digit year (e.g., 99) %Y Four-digit year (e.g., 1999) %A Full weekday (e.g., Monday) %a Abberviated weekday (e.g., Mon) Here are some examples of what you would specify for the format argument of as.Date for some different original formats of date columns: Your date format 10/23/2008 “%m/%d%Y” 08-10-23 “%y-%m-%d” Oct. 23 2008 “%b. %d %Y” October 23, 2008 “%B %d, %Y” Thurs, 23 October 2008 “%a, %d %B %Y” You must use the format argument to specify what your date column looks like before it’s converted to a Date class, not how you’d like it to look after its converted. Once an objects is in a date class, it will always be printed out using a common format, unless you change it back into a character class. (Confusingly, there is a format function that you can use to convert from a Date class to a character class and, in that case, the format argument does specify how the final date will look. This is mainly useful as a last step in data analysis, when you’re creating plot labels of table columns, for example.) There is also a function in the tidyverse, called lubridate, that helps in parsing dates. In many cases you can use functions from this package to parse dates much more easily, without having to specify specific starting formats. The ymd function from lubridate can be used to parse a column into a Date clase, regardless of the original format of the date, as long as the date elements are in the order: year, month, day. For example: library(lubridate) ymd(&quot;2008-10-13&quot;) ## [1] &quot;2008-10-13&quot; ymd(&quot;&#39;08 Oct 13&quot;) ## [1] &quot;2008-10-13&quot; ymd(&quot;&#39;08 Oct 13&quot;) ## [1] &quot;2008-10-13&quot; The lubridate package has similar functions for other date orders or for date-times, including: dmy mdy ymd_h ymd_hm We could have used these to transform the date in daily_show, using the following pipe chain: daily_show &lt;- read_csv(&quot;data/daily_show_guests.csv&quot;, skip = 4) %&gt;% rename(job = GoogleKnowlege_Occupation, date = Show, category = Group, guest_name = Raw_Guest_List) %&gt;% select(-YEAR) %&gt;% mutate(date = mdy(date)) %&gt;% filter(category == &quot;Science&quot;) head(daily_show, 2) ## # A tibble: 2 × 4 ## job date category guest_name ## &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; ## 1 neurosurgeon 2003-04-28 Science Dr Sanjay Gupta ## 2 scientist 2004-01-13 Science Catherine Weitz The lubridate package also includes functions to pull out certain elements of a date, including: wday mday yday month quarter year For example, we could use wday to create a new column with the weekday of each show: mutate(daily_show, show_day = wday(date, label = TRUE)) %&gt;% select(date, show_day, guest_name) %&gt;% slice(1:5) ## # A tibble: 5 × 3 ## date show_day guest_name ## &lt;date&gt; &lt;ord&gt; &lt;chr&gt; ## 1 2003-04-28 Mon Dr Sanjay Gupta ## 2 2004-01-13 Tues Catherine Weitz ## 3 2004-06-15 Tues Hassan Ibrahim ## 4 2005-09-06 Tues Dr. Marc Siegel ## 5 2006-02-13 Mon Astronaut Mike Mullane 2.7 In-course Exercise 2.7.1 Checking out directory structures Download the whole directory for this week from Github. Put the “data” directory as a subdirectory in your directory for this class. To do that, go the the GitHub page for the course and, in the top right, choose “Clone or Download” and then choose “Download ZIP”. Then move the “data” subdirectory into your course directory and throw away rest of what you downloaded. Unfortunately, while GitHub will let you download data files one at a time, it doesn’t offer a straightforward way of downloading a whole subdirectory from a repository. For this task, where you’re pulling all of the data in the “data” subdirectory of the course repository, the quickest method is to download the entire directory, find and move the subdirectory that you need, and then delete the rest. Look through the structure of the “data” directory. What files are in the directory? What subdirectories? Sketch out the structure of this directory. Create a new R script to put all the code you use for this exercise. Create a subdirectory in your course directory called “R” and save this script there using a .R extension (e.g., “week_2.R”). 2.7.2 Using relative and absolute file pathnames Once you have the data, I’d like you to try using setwd() to move around the directories on your computer. For this section of the exercise, you’ll try to open the same file from different working directories, to get practice using absolute and relative file pathnames. Start by changing your working directory to the “data” subdirectory you just downloaded. For me, the absolute path to that is /Users/brookeanderson/RProgrammingForResearch/data, so to change my working directory to this one using an absolute file pathname, I would run: setwd(&quot;/Users/brookeanderson/RProgrammingForResearch/data&quot;) getwd() The absolute pathname will be different for each person, based on the directories on his or her computer and where he or she saved this particular directory. Since “~” is shorthand for my home directory (“/Users/brookeanderson”), I could also use the absolute pathname “~/RProgrammingForResearch/data” when setting this directory as my working directory. Now, use the list.files function to make sure you have all the files that you just pulled in your current working directory: list.files() ## [1] &quot;country_timeseries.csv&quot; &quot;daily_show_guests.csv&quot; ## [3] &quot;deaths-weather.csv&quot; &quot;icd-10.xls&quot; ## [5] &quot;ICU_Data_Code_Sheet.pdf&quot; &quot;icu.sas7bdat&quot; ## [7] &quot;ld_genetics.txt&quot; &quot;measles_data&quot; Try the following tasks: Read in the ebola data in country_timeseries.csv. Save it as the R object ebola. How many rows and columns does it have? What are the names of the columns? Now try moving up one directory from your current working directory (which should be the “data” directory), into the directory you created for this course. What happens if you use the same code as before to read in the file? What do you need to change to be able to read the file in from here? Try to read in the data from here using: A relative pathname An absolute pathname Now move down into the subdirectory of “data” called “measles_data”. Try to read in the Ebola data from this working directory using: A relative pathname An absolute pathname Which method (absolute or relative pathnames) always used the same code, regardless of your current working directory? Which method used different code, depending on the starting working directory? Example R code: getwd() ## Make sure you&#39;re in the &quot;data&quot; directory to start ## [1] &quot;/Users/brookeanderson/RProgrammingForResearch/data&quot; ebola &lt;- read.csv(&quot;country_timeseries.csv&quot;, header = TRUE) ebola[1:5, 1:5] ## Date Day Cases_Guinea Cases_Liberia Cases_SierraLeone ## 1 1/5/2015 289 2776 NA 10030 ## 2 1/4/2015 288 2775 NA 9780 ## 3 1/3/2015 287 2769 8166 9722 ## 4 1/2/2015 286 NA 8157 NA ## 5 12/31/2014 284 2730 8115 9633 dim(ebola) # To figure out number of rows and columns ## [1] 122 18 colnames(ebola) # To figure out column names ## [1] &quot;Date&quot; &quot;Day&quot; &quot;Cases_Guinea&quot; ## [4] &quot;Cases_Liberia&quot; &quot;Cases_SierraLeone&quot; &quot;Cases_Nigeria&quot; ## [7] &quot;Cases_Senegal&quot; &quot;Cases_UnitedStates&quot; &quot;Cases_Spain&quot; ## [10] &quot;Cases_Mali&quot; &quot;Deaths_Guinea&quot; &quot;Deaths_Liberia&quot; ## [13] &quot;Deaths_SierraLeone&quot; &quot;Deaths_Nigeria&quot; &quot;Deaths_Senegal&quot; ## [16] &quot;Deaths_UnitedStates&quot; &quot;Deaths_Spain&quot; &quot;Deaths_Mali&quot; ## Move up one directory setwd(&quot;..&quot;) getwd() ## Get the file using the relative pathname ebola &lt;- read.csv(&quot;data/country_timeseries.csv&quot;, header = TRUE) ebola[1:5, 1:5] ## Date Day Cases_Guinea Cases_Liberia Cases_SierraLeone ## 1 1/5/2015 289 2776 NA 10030 ## 2 1/4/2015 288 2775 NA 9780 ## 3 1/3/2015 287 2769 8166 9722 ## 4 1/2/2015 286 NA 8157 NA ## 5 12/31/2014 284 2730 8115 9633 ## Get the file using the absolute pathname abs_path &lt;- paste0(&quot;/Users/brookeanderson/RProgrammingForResearch/&quot;, &quot;data/country_timeseries.csv&quot;) abs_path ## [1] &quot;/Users/brookeanderson/RProgrammingForResearch/data/country_timeseries.csv&quot; ebola &lt;- read.csv(abs_path, header = TRUE) ebola[1:5, 1:5] ## Date Day Cases_Guinea Cases_Liberia Cases_SierraLeone ## 1 1/5/2015 289 2776 NA 10030 ## 2 1/4/2015 288 2775 NA 9780 ## 3 1/3/2015 287 2769 8166 9722 ## 4 1/2/2015 286 NA 8157 NA ## 5 12/31/2014 284 2730 8115 9633 ## Reset your working directory as your directory for this course ## and then check that you&#39;re in the right place getwd() ## [1] &quot;/Users/brookeanderson/RProgrammingForResearch&quot; ## Move into the measles_data subdirectory setwd(&quot;data/measles_data&quot;) getwd() ## [1] &quot;/Users/brookeanderson/RProgrammingForResearch/data/measles_data&quot; ## Get the file using the relative pathname ebola &lt;- read.csv(&quot;../country_timeseries.csv&quot;, header = TRUE) ebola[1:5, 1:5] ## Date Day Cases_Guinea Cases_Liberia Cases_SierraLeone ## 1 1/5/2015 289 2776 NA 10030 ## 2 1/4/2015 288 2775 NA 9780 ## 3 1/3/2015 287 2769 8166 9722 ## 4 1/2/2015 286 NA 8157 NA ## 5 12/31/2014 284 2730 8115 9633 # Get the file using the absolute pathname (note: we&#39;ve already assigned # the absolute pathname in the `abs_path` object, so we can just use that # object in the `read.csv` call here, rather than typing out the full # absolute pathname again.) ebola &lt;- read.csv(abs_path, header = TRUE) ebola[1:5, 1:5] ## Date Day Cases_Guinea Cases_Liberia Cases_SierraLeone ## 1 1/5/2015 289 2776 NA 10030 ## 2 1/4/2015 288 2775 NA 9780 ## 3 1/3/2015 287 2769 8166 9722 ## 4 1/2/2015 286 NA 8157 NA ## 5 12/31/2014 284 2730 8115 9633 If you have extra time: Find out some more about this Ebola dataset by checking out Caitlin Rivers’ Ebola data GitHub repository. Who is Caitlin Rivers? How did she put this dataset together? Search for R code related to Ebola research on GitHub. Go to the GitHub home page and use the search bar to search for “ebola”. On the results page, scroll down and use the “Language” sidebar on the left to choose repositories with R code. Did you find any interesting projects? When you list.files() when your working directory is the “data” directory, almost everything listed has a file extension, like .csv, .xls, .sas7bdat. One thing does not. Which one? Why does this listing not have a file extension? 2.7.3 Reading in different types of files First, make sure your reset your working directory to your course directory: setwd(&quot;~/RProgrammingForResearch/&quot;) Now you’ll try reading in data from a variety of types of file formats. All of these files are stored in the “data” subdirectory of your current working directory, so you’ll use filenames throughout that start with “data/”. Try the following tasks: What type of flat file do you think the “ld_genetics.txt” file is? See if you can read it in and save it as the R object ld_genetics. Use the summary function to check out basic statistics on the data. Check out the file “measles_data/02-09-2015.txt”. What type of flat file do you think it is? Stay in the “data” directory and use a relative pathname to read the file in and save it as the R object ca_measles. Use the col.names option to name the columns “city” and “count”. What would the default column names be if you didn’t use this option? Read in the Excel file “icd-10.xls” and assign it to the object name idc10. Use the readxl package to do that (examples are at the bottom of the linked page). Read in the SAS file icu.sas7bdat. To do this, use the haven package. Read the file into the R object icu. Example R code: ld_genetics &lt;- read.delim(&quot;data/ld_genetics.txt&quot;, header = TRUE) summary(ld_genetics) ## pos nA nC nG ## Min. : 500 Min. :185 Min. :120.0 Min. : 85.0 ## 1st Qu.: 876000 1st Qu.:288 1st Qu.:173.0 1st Qu.:172.0 ## Median :1751500 Median :308 Median :190.0 Median :189.0 ## Mean :1751500 Mean :309 Mean :191.9 Mean :191.8 ## 3rd Qu.:2627000 3rd Qu.:329 3rd Qu.:209.0 3rd Qu.:208.0 ## Max. :3502500 Max. :463 Max. :321.0 Max. :326.0 ## nT GCsk TAsk cGCsk ## Min. :188.0 Min. :-189.0000 Min. :-254.000 Min. : -453 ## 1st Qu.:286.0 1st Qu.: -30.0000 1st Qu.: -36.000 1st Qu.:10796 ## Median :306.0 Median : 0.0000 Median : -2.000 Median :23543 ## Mean :307.2 Mean : -0.1293 Mean : -1.736 Mean :22889 ## 3rd Qu.:328.0 3rd Qu.: 29.0000 3rd Qu.: 32.500 3rd Qu.:34940 ## Max. :444.0 Max. : 134.0000 Max. : 205.000 Max. :46085 ## cTAsk ## Min. :-6247 ## 1st Qu.: 1817 ## Median : 7656 ## Mean : 7855 ## 3rd Qu.:15036 ## Max. :19049 ca_measles &lt;- read.delim(&quot;data/measles_data/02-09-2015.txt&quot;, header = FALSE, col.names = c(&quot;city&quot;, &quot;count&quot;)) head(ca_measles) ## city count ## 1 ALAMEDA 6 ## 2 LOS ANGELES 20 ## 3 City of Long Beach 2 ## 4 City of Pasadena 4 ## 5 MARIN 2 ## 6 ORANGE 34 library(readxl) icd10 &lt;- read_excel(&quot;data/icd-10.xls&quot;) ## DEFINEDNAME: 20 00 00 01 0b 00 00 00 01 00 00 00 00 00 00 06 3b 00 00 00 00 51 2b 00 00 0a 00 ## DEFINEDNAME: 20 00 00 01 0b 00 00 00 01 00 00 00 00 00 00 06 3b 00 00 00 00 51 2b 00 00 0a 00 ## DEFINEDNAME: 20 00 00 01 0b 00 00 00 01 00 00 00 00 00 00 06 3b 00 00 00 00 51 2b 00 00 0a 00 ## DEFINEDNAME: 20 00 00 01 0b 00 00 00 01 00 00 00 00 00 00 06 3b 00 00 00 00 51 2b 00 00 0a 00 head(icd10) ## # A tibble: 6 × 2 ## Code `ICD Title` ## &lt;chr&gt; &lt;chr&gt; ## 1 A00-B99 I. Certain infectious and parasitic diseases ## 2 A00-A09 Intestinal infectious diseases ## 3 A00 Cholera ## 4 A00.0 Cholera due to Vibrio cholerae 01, biovar cholerae ## 5 A00.1 Cholera due to Vibrio cholerae 01, biovar eltor ## 6 A00.9 Cholera, unspecified library(haven) ## ## Attaching package: &#39;haven&#39; ## The following object is masked from &#39;package:lubridate&#39;: ## ## hms icu &lt;- read_sas(&quot;data/icu.sas7bdat&quot;) icu[1:5, 1:5] ## # A tibble: 5 × 5 ## ID STA AGE GENDER RACE ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 1 87 1 1 ## 2 8 0 27 1 1 ## 3 12 0 59 0 1 ## 4 14 0 77 0 1 ## 5 27 1 76 1 1 If you have extra time: Is there a way to read the “ld_genetics.txt” file in using read.table() and specific options? If so, try to read the data in using that function. Why can you use both read.delim and read.table to read in this file? Example R code: ## Using the read.table function ld_genetics &lt;- read.table(&quot;data/ld_genetics.txt&quot;, header = TRUE, sep = &quot;\\t&quot;) ld_genetics[1:5, 1:5] ## pos nA nC nG nT ## 1 500 307 153 192 348 ## 2 1500 310 169 207 314 ## 3 2500 319 167 177 337 ## 4 3500 373 164 168 295 ## 5 4500 330 175 224 271 2.7.4 Cleaning up data Try out the following tasks: You now have an R object called ebola. Create an object called ebola_liberia that only has the columns with the Date and cases and deaths in Liberia. How many observations do you have? Change the column names to date, cases, and deaths. What class is the date column currently in? Convert it to a Date object. If it’s currently a factor, you will need to first convert it to a character (do you know why)? What are the starting and ending dates of this data? This data has earliest dates last and latest dates first. Often, we want our data in chronological order. Change the dataset so it’s in chronological order. Hint: You can use row indices to do this, if you use row indices to list the data from last row to first. For example, what do you get if you do 3:1? What about if you do ebola[3:1, ]? Think of how you can extend this, along with nrow() do this task. There are a number of different ways to do this step, and we’ll talk about more ways later in the course. Example R code: library(dplyr) ## Create a subset with just the Liberia columns and Date ebola_liberia &lt;- select(ebola, Date, Cases_Liberia, Deaths_Liberia) head(ebola_liberia) ## Date Cases_Liberia Deaths_Liberia ## 1 1/5/2015 NA NA ## 2 1/4/2015 NA NA ## 3 1/3/2015 8166 3496 ## 4 1/2/2015 8157 3496 ## 5 12/31/2014 8115 3471 ## 6 12/28/2014 8018 3423 ## How many rows does the whole dataset have? nrow(ebola_liberia) ## [1] 122 ## Rename the columns ebola_liberia &lt;- rename(ebola_liberia, date = Date, cases = Cases_Liberia, deaths = Deaths_Liberia) ebola_liberia[1:3, ] ## date cases deaths ## 1 1/5/2015 NA NA ## 2 1/4/2015 NA NA ## 3 1/3/2015 8166 3496 ## What class is the `date` column? class(ebola_liberia$date) ## [1] &quot;factor&quot; ## Use the `mdy` from `lubridate` to convert to Date class library(lubridate) ebola_liberia &lt;- mutate(ebola_liberia, date = mdy(date)) head(ebola_liberia$date) ## [1] &quot;2015-01-05&quot; &quot;2015-01-04&quot; &quot;2015-01-03&quot; &quot;2015-01-02&quot; &quot;2014-12-31&quot; ## [6] &quot;2014-12-28&quot; ## What are the starting and ending dates? range(ebola_liberia$date) ## [1] &quot;2014-03-22&quot; &quot;2015-01-05&quot; ## Re-order the dataset from last to first ebola_liberia &lt;- ebola_liberia[nrow(ebola_liberia):1, ] ebola_liberia[1:3, ] ## date cases deaths ## 122 2014-03-22 NA NA ## 121 2014-03-24 NA NA ## 120 2014-03-25 NA NA If you have extra time: Limit the ebola_liberia dataset just to the days with non-missing case data. How many observations do you have now? Write a pipe chain for the full data cleaning process for creating ebola_liberia up to this point. Hint: Try using the arrange function from dplyr to re-order the data by dates in this pipe. Try using the basic plotting function, plot(), to plot the number of cases over time. Do you think that the cases variable is measuring the count of cases for that day, or the cumulative number of cases up to that day? See if you can figure out more on Caitlin Rivers’ GitHub documentation. Do you notice any potential data quality issues in this data? Hint: The plot() function takes, as required arguments, the vector you want to plot on the x-axis and then the vector you want to plot on the y-axis, like plot([x vector], [y vector]). If you are pulling the vectors from a dataset, you will need to use indexing to pull out the column you want as a vector, like plot([dataframe name]$[column name for x], [dataframe]$[column name for y]). Example R code: ## Remove observations with missing cases ebola_liberia &lt;- filter(ebola_liberia, !is.na(cases)) nrow(ebola_liberia) ## [1] 83 ## Rewrite the data cleaning for `ebola_liberia` using a pipe chain ebola_liberia &lt;- ebola %&gt;% select(Date, Cases_Liberia, Deaths_Liberia) %&gt;% rename(date = Date, cases = Cases_Liberia, deaths = Deaths_Liberia) %&gt;% mutate(date = mdy(date)) %&gt;% arrange(date) %&gt;% filter(!is.na(cases)) ## Plot the data plot(ebola_liberia$date, ebola_liberia$cases) 2.7.5 A taste of what’s to come… Here’s an example to give you a feel for why it’s worth learning all these different things about directories, list.files, and pathnames. The measles_data subdirectory includes counts of measles made at different times in different cities in California. Say that we wanted to read them all in and make put them into one long dataframe with the variables city, count, and date. You can put together the things you’ve learned so far, along with a few new ideas (including doing a loop), to do this very easily. We’ll talk more later about using loops and functions to make your programming more efficient, but for right now just look through this code and see if you can get a feel for how it’s working (make sure your directory for this course is your working directory): ## Create a vector of all the file names in the `measles_data` subdirectory measles_files &lt;- list.files(&quot;data/measles_data&quot;) measles_files ## [1] &quot;02-09-2015.txt&quot; &quot;02-11-2015.txt&quot; &quot;02-13-2015.txt&quot; &quot;02-18-2015.txt&quot; ## [5] &quot;02-20-2015.txt&quot; &quot;02-23-2015.txt&quot; &quot;02-25-2015.txt&quot; &quot;02-27-2015.txt&quot; ## [9] &quot;03-02-2015.txt&quot; &quot;03-06-2015.txt&quot; &quot;03-13-2015.txt&quot; &quot;03-20-2015.txt&quot; ## [13] &quot;03-27-2015.txt&quot; &quot;04-03-2015.txt&quot; &quot;04-10-2015.txt&quot; &quot;04-17-2015.txt&quot; ## Create a vector of all the dates for files by taking the ## `.txt` off each of these file names and change it into ## a date measles_dates &lt;- sub(&quot;.txt&quot;, &quot;&quot;, measles_files) measles_dates ## [1] &quot;02-09-2015&quot; &quot;02-11-2015&quot; &quot;02-13-2015&quot; &quot;02-18-2015&quot; &quot;02-20-2015&quot; ## [6] &quot;02-23-2015&quot; &quot;02-25-2015&quot; &quot;02-27-2015&quot; &quot;03-02-2015&quot; &quot;03-06-2015&quot; ## [11] &quot;03-13-2015&quot; &quot;03-20-2015&quot; &quot;03-27-2015&quot; &quot;04-03-2015&quot; &quot;04-10-2015&quot; ## [16] &quot;04-17-2015&quot; class(measles_dates) ## [1] &quot;character&quot; measles_dates &lt;- mdy(measles_dates) measles_dates ## [1] &quot;2015-02-09&quot; &quot;2015-02-11&quot; &quot;2015-02-13&quot; &quot;2015-02-18&quot; &quot;2015-02-20&quot; ## [6] &quot;2015-02-23&quot; &quot;2015-02-25&quot; &quot;2015-02-27&quot; &quot;2015-03-02&quot; &quot;2015-03-06&quot; ## [11] &quot;2015-03-13&quot; &quot;2015-03-20&quot; &quot;2015-03-27&quot; &quot;2015-04-03&quot; &quot;2015-04-10&quot; ## [16] &quot;2015-04-17&quot; ## Before I show the loop, let me talk you through some ## of the parts of it: i &lt;- 1 # I&#39;m setting the index to 1 ## Now I&#39;ll use `paste0` to create the first file name ## I want to read. file_name &lt;- paste0(&quot;data/measles_data/&quot;, measles_files[i]) file_name ## [1] &quot;data/measles_data/02-09-2015.txt&quot; ## Now I&#39;ll read in that tab-delimited file df &lt;- read_tsv(file_name, col_names = c(&quot;city&quot;, &quot;count&quot;)) head(df) ## # A tibble: 6 × 2 ## city count ## &lt;chr&gt; &lt;int&gt; ## 1 ALAMEDA 6 ## 2 LOS ANGELES 20 ## 3 City of Long Beach 2 ## 4 City of Pasadena 4 ## 5 MARIN 2 ## 6 ORANGE 34 ## Now I&#39;ll add on a column with the date for all the ## values from that file. Notice that I&#39;m using `i` to ## index this, as well df &lt;- mutate(df, date = measles_dates[i]) head(df) ## # A tibble: 6 × 3 ## city count date ## &lt;chr&gt; &lt;int&gt; &lt;date&gt; ## 1 ALAMEDA 6 2015-02-09 ## 2 LOS ANGELES 20 2015-02-09 ## 3 City of Long Beach 2 2015-02-09 ## 4 City of Pasadena 4 2015-02-09 ## 5 MARIN 2 2015-02-09 ## 6 ORANGE 34 2015-02-09 ## Loop through and read in files. After the first file, ## add on the new information to the data that&#39;s already ## been read in. Note that you can use `rbind` to add on ## new rows to a dataframe as long as the new and old rows ## have the same number of columns and the same column names. for(i in 1:length(measles_files)){ file_name &lt;- paste0(&quot;data/measles_data/&quot;, measles_files[i]) df &lt;- read.delim(file_name, header = FALSE, col.names = c(&quot;city&quot;, &quot;count&quot;)) df &lt;- mutate(df, date = measles_dates[i]) if(i == 1){ ca_measles &lt;- df } else { ca_measles &lt;- rbind(ca_measles, df) } } dim(ca_measles) ## [1] 232 3 summary(ca_measles) ## city count date ## ALAMEDA : 16 Min. : 1.000 Min. :2015-02-09 ## City of Long Beach: 16 1st Qu.: 2.000 1st Qu.:2015-02-20 ## City of Pasadena : 16 Median : 4.000 Median :2015-03-02 ## LOS ANGELES : 16 Mean : 8.698 Mean :2015-03-07 ## MARIN : 16 3rd Qu.:12.000 3rd Qu.:2015-03-27 ## ORANGE : 16 Max. :35.000 Max. :2015-04-17 ## (Other) :136 library(ggplot2) ggplot(subset(ca_measles, city %in% c(&quot;LOS ANGELES&quot;, &quot;SAN DIEGO&quot;, &quot;ORANGE&quot;)), aes(x = date, y = count)) + geom_line() + facet_grid(. ~ city) "],
["exploring-data-1.html", "Chapter 3 Exploring data #1 3.1 Data from a package 3.2 Plots to explore data 3.3 Simple statistics functions 3.4 Logical vectors 3.5 Regression models 3.6 In-course exercise", " Chapter 3 Exploring data #1 Download a pdf of the lecture slides covering this topic. 3.1 Data from a package So far we’ve covered three ways to get data into R: From flat files (either on your computer or online) From files like SAS and Excel From R objects (i.e., using load()) Many R packages come with their own data, which is very easy to load and use. For example, the faraway package has a dataset called worldcup that you’ll use today. To load it, use the data() function once you’ve loaded the package: library(faraway) data(&quot;worldcup&quot;) Unlike most data objects you’ll work with, the data that comes with an R package will often have its own help file. You can access this using the ? operator: ?worldcup To find out all the datasets that are available in the packages you currently have loaded, run data() without an option inside the parentheses: data() As a note, you can similarly use library(), without the name of a package, to list all of the packages you have installed that you could call with library(): library() 3.2 Plots to explore data Plots can be invaluable in exploring your data. In this section, I will focus on teaching you the basics of ggplot2 plotting. This section will focus on making useful, rather than attractive graphs, since we are focusing on exploring rather than presenting data at this stage. In a later section, I will discuss customization of ggplot2 plots, to help you make more attractive plots that would go into final reports. This chapter covers how to make the following types of basic plots using functions from the ggplot2 package (another member of the tidyverse!): library(ggplot2) The basic steps behind creating a plot with ggplot2 are: You’ll create an object of the ggplot class, typically specifying the data and some or all of the aesthetics; You’ll add on geoms and other elements to create and customize the plot, using +. Note: To avoid errors, end lines with +, don’t start lines with it. 3.2.1 Initializing a ggplot object Use the following conventions to initialize a ggplot object: ## Generic code object &lt;- ggplot(dataframe, aes(x = column_1, y = column_2)) Notice that you first specify the dataframe with the data you want to plot and then you might specify either mappings or constant values for some or all of the aesthetics (aes). 3.2.2 Plot aesthetics Aesthetics are elements that can show certain elements of the data. For example, color might show gender, x-position might show height, and y-position might show weight. In this graph, the mapped aesthetics are color, x, and y. Note: Any of these aesthetics could also be given a constant value, instead of being mapped to an element of the data. For example, all the points could be red, instead of showing gender. Here are some common plot aesthetics you might want to specify: Code Description x Position on x-axis y Position on y-axis shape Shape color Color of border of elements fill Color of inside of elements size Size alpha Transparency (1: opaque; 0: transparent) linetype Type of line (e.g., solid, dashed) Which aesthetics you must specify depend on which geoms (more on those in a second) you’re adding to the plot. You can find out the aesthetics you can use for a geom in the “Aesthetics” section of the geom’s help file (e.g., ?geom_point). Required aesthetics are in bold in this section of the help file and optional ones are not. 3.2.3 Adding geoms Next, you’ll want to add one or more geoms to create the plot. You can add these with + after the ggplot statement to initialize the ggplot object. Some of the most common geoms are: Plot type ggplot2 function Histogram (1 numeric variable) geom_histogram Scatterplot (2 numeric variables) geom_point Boxplot (1 numeric variable, possibly 1 factor variable) geom_boxplot Line graph (2 numeric variables) geom_line 3.2.4 Constant aesthetics Instead of mapping an aesthetic to an element of your data, you can use a constant value for it. For example, you may want to make all the points green, rather than having color map to gender: In this case, you’ll define that aesthetic when you add the geom, outside of an aes statement. If you’re using a constant shape, you specify the shape with a number. Here are the shapes that correspond to the numbers 1 to 25: If you are using a constant color, R has character names for different colors. For example: Google “R colors” and search the images to find links to listings of different R colors. 3.2.5 Useful plot additions There are also a number of elements that you can add onto a ggplot object using +. A few very frequently used ones are: Element Description ggtitle Plot title xlab, ylab x- and y-axis labels xlim, ylim Limits of x- and y-axis 3.2.6 Example dataset For the example plots, I’ll use a dataset in the faraway package called nepali. This gives data from a study of the health of a group of Nepalese children. library(faraway) data(nepali) I’ll be using functions from dplyr and ggplot2, so those need to be loaded: library(dplyr) library(ggplot2) Each observation is a single measurement for a child; there can be multiple observations per child. I’ll subset out child id, sex, weight, height, and age, and I’ll limit to each child’s first measurement. nepali &lt;- nepali %&gt;% # Subset to certain columns select(id, sex, wt, ht, age) %&gt;% # Convert id and sex to factors mutate(id = factor(id), sex = factor(sex, levels = c(1, 2), labels = c(&quot;Male&quot;, &quot;Female&quot;))) %&gt;% # Limit to first obs. per child distinct(id, .keep_all = TRUE) The data now looks like: head(nepali) ## id sex wt ht age ## 1 120011 Male 12.8 91.2 41 ## 2 120012 Female 14.9 103.9 57 ## 3 120021 Female 7.7 70.1 8 ## 4 120022 Female 12.1 86.4 35 ## 5 120023 Male 14.2 99.4 49 ## 6 120031 Male 13.9 96.4 46 3.2.7 Histograms For geom_histogram(), the main aesthetic is x, the (numeric) vector for which you want to create a histogram: ggplot(nepali, aes(x = ht)) + geom_histogram() You can add some elements to the histogram, like ggtitle, xlab, and xlim: ggplot(nepali, aes(x = ht)) + geom_histogram(fill = &quot;lightblue&quot;, color = &quot;black&quot;) + ggtitle(&quot;Height of children&quot;) + xlab(&quot;Height (cm)&quot;) + xlim(c(0, 120)) geom_histogram also has its own special argument, bins. You can use this to change the number of bins that are used to make the histogram: ggplot(nepali, aes(x = ht)) + geom_histogram(fill = &quot;lightblue&quot;, color = &quot;black&quot;, bins = 40) 3.2.8 Scatterplots You can use the geom_point geom to create a scatterplot. For example, to create a scatterplot of height versus age for the Nepali data: ggplot(nepali, aes(x = ht, y = wt)) + geom_point() Again, you can use some of the options and additions to change the plot appearance: ggplot(nepali, aes(x = ht, y = wt)) + geom_point(color = &quot;blue&quot;, size = 0.5) + ggtitle(&quot;Weight versus Height&quot;) + xlab(&quot;Height (cm)&quot;) + ylab(&quot;Weight (kg)&quot;) You can also try mapping another variable, sex, to the color aesthetic: ggplot(nepali, aes(x = ht, y = wt, color = sex)) + geom_point(size = 0.5) + ggtitle(&quot;Weight versus Height&quot;) + xlab(&quot;Height (cm)&quot;) + ylab(&quot;Weight (kg)&quot;) 3.2.9 Boxplots To create a boxplot, use geom_boxplot: ggplot(nepali, aes(x = 1, y = ht)) + geom_boxplot() + xlab(&quot;&quot;)+ ylab(&quot;Height (cm)&quot;) You can also create separate boxplots, one for each level of a factor. In this case, you’ll need to include two aesthetics (x and y) when you initialize the ggplot object. ggplot(nepali, aes(x = sex, y = ht, group = sex)) + geom_boxplot() + xlab(&quot;Sex&quot;)+ ylab(&quot;Height (cm)&quot;) 3.2.10 Extensions of ggplot2 There are lots of R extensions for creating other interesting plots. For example, you can use the ggpairs function from the GGally package to plot all pairs of scatterplots for several variables. Notice how this output shows continuous and binary variables differently. library(GGally) ggpairs(nepali[, c(&quot;sex&quot;, &quot;wt&quot;, &quot;ht&quot;, &quot;age&quot;)]) 3.3 Simple statistics functions Here are some simple statistics functions you will likely use often: Function Description range() Range (minimum and maximum) of vector min(), max() Minimum or maximum of vector mean(), median() Mean or median of vector table() Number of observations per level for a factor vector cor() Determine correlation(s) between two or more vectors summary() Summary statistics, depends on class All of these take, as the main argument, the vector(s) for which you want the statistic. If there are missing values in the vector, you’ll need to add an option to say what to do when them (e.g., na.rm or use=&quot;complete.obs&quot;). mean(nepali$wt, na.rm = TRUE) ## [1] 10.18432 range(nepali$ht, na.rm = TRUE) ## [1] 52.4 104.1 table(nepali$sex) ## ## Male Female ## 107 93 The cor function can take two or more vectors. If you give it multiple values, it will give the correlation matrix for all the vectors. cor(nepali$wt, nepali$ht, use = &quot;complete.obs&quot;) ## [1] 0.9571535 cor(nepali[ , c(&quot;wt&quot;, &quot;ht&quot;, &quot;age&quot;)], use = &quot;complete.obs&quot;) ## wt ht age ## wt 1.0000000 0.9571535 0.8931195 ## ht 0.9571535 1.0000000 0.9287129 ## age 0.8931195 0.9287129 1.0000000 R supports object-oriented programming. This shows up with summary(). R looks to see what type of object it’s dealing with, and then uses a method specific to that object type. summary(nepali$wt) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 3.80 7.90 10.10 10.18 12.40 16.70 15 summary(nepali$sex) ## Male Female ## 107 93 We’ll see more of this when we do regression models. You can also perform many of these tasks using dplyr. For example, to get the mean weight, you can use the summarize function: nepali %&gt;% summarize(mean_wt = mean(wt, na.rm = TRUE)) ## mean_wt ## 1 10.18432 There are some special functions that you can use with summarize. For example, n and first (see the Data Wrangling cheatsheet for more): nepali %&gt;% summarize(n_children =n(), first_id = first(id)) ## n_children first_id ## 1 200 120011 If you want to get summaries by group using dplyr (e.g., mean weight by sex), use group_by before running summarize: nepali %&gt;% group_by(sex) %&gt;% summarize(mean_wt = mean(wt, na.rm = TRUE), n_children =n(), first_id = first(id)) ## # A tibble: 2 × 4 ## sex mean_wt n_children first_id ## &lt;fctr&gt; &lt;dbl&gt; &lt;int&gt; &lt;fctr&gt; ## 1 Male 10.497980 107 120011 ## 2 Female 9.823256 93 120012 3.4 Logical vectors Last week, you learned a lot about logical statements and how to use them with the subset() function. You can also use logical vectors, created with these statements, for a lot of other things. For example, you can use them directly in the square bracket indexing ([..., ...]). A logical statement run on a vector will create a logical vector the same length as the original vector: is_male &lt;- nepali$sex == &quot;Male&quot; length(nepali$sex) ## [1] 200 length(is_male) ## [1] 200 The logical vector will have the value TRUE at any position where the original vector met the logical condition you tested, and FALSE anywhere else: head(nepali$sex) ## [1] Male Female Female Female Male Male ## Levels: Male Female head(is_male) ## [1] TRUE FALSE FALSE FALSE TRUE TRUE You can “flip” this logical vector (i.e., change every TRUE to FALSE and vice-versa) using !: head(is_male) ## [1] TRUE FALSE FALSE FALSE TRUE TRUE head(!is_male) ## [1] FALSE TRUE TRUE TRUE FALSE FALSE You can do a few cool things now with this vector. For example, you can use it with indexing to pull out just the rows where is_male is TRUE: head(nepali[is_male, ]) ## id sex wt ht age ## 1 120011 Male 12.8 91.2 41 ## 5 120023 Male 14.2 99.4 49 ## 6 120031 Male 13.9 96.4 46 ## 7 120051 Male 8.3 69.5 8 ## 9 120053 Male 15.8 96.0 54 ## 11 120062 Male 12.1 89.9 57 Or, with !, just the rows where is_male is FALSE: head(nepali[!is_male, ]) ## id sex wt ht age ## 2 120012 Female 14.9 103.9 57 ## 3 120021 Female 7.7 70.1 8 ## 4 120022 Female 12.1 86.4 35 ## 8 120052 Female 11.8 83.6 32 ## 10 120061 Female 8.7 78.5 26 ## 15 120082 Female 11.2 79.8 36 You can also use sum() and table() to find out how many males and females are in the dataset: sum(is_male); sum(!is_male) ## [1] 107 ## [1] 93 table(is_male) ## is_male ## FALSE TRUE ## 93 107 As a note, you could achieve the same thing with dplyr functions. One way to do this is to use mutate with a logical statement to create an is_male column, then group by that new column and summarize: nepali %&gt;% mutate(is_male = sex == &quot;Male&quot;) %&gt;% group_by(is_male) %&gt;% summarize(n_children = n()) ## # A tibble: 2 × 2 ## is_male n_children ## &lt;lgl&gt; &lt;int&gt; ## 1 FALSE 93 ## 2 TRUE 107 3.5 Regression models 3.5.1 Formula structure Regression models can be used to estimate how the expected value of a dependent variable changes as independent variables change. In R, regression formulas take this structure: ## Generic code [response variable] ~ [indep. var. 1] + [indep. var. 2] + ... Notice that ~ used to separate the independent and dependent variables and the + used to join independent variables. This format mimics the statistical notation: \\[ Y_i \\sim X_1 + X_2 + X_3 \\] You will use this type of structure in R fo a lot of different function calls, including those for linear models (lm) and generalized linear models (glm). 3.5.2 Linear models To fit a linear model, you can use the function lm(). Use the data option to specify the dataframe from which to get the vectors. You can save the model as an object. mod_a &lt;- lm(wt ~ ht, data = nepali) This call fits the model: \\[ Y_{i} = \\beta_{0} + \\beta_{1}X_{1,i} + \\epsilon_{i} \\] where: \\(Y_{i}\\) : weight of child \\(i\\) \\(X_{1,i}\\) : height of child \\(i\\) Some functions you can use on model objects: Function Description summary Get a variety of information on the model, including coefficients and p-values for the coefficients coef Pull out just the coefficients for a model fitted Get the fitted values from the model (for the data used to fit the model) plot Create plots to help assess model assumptions residuals Get the model residuals For example, you can get the coefficients from the model we just fit: coef(mod_a) ## (Intercept) ht ## -8.694768 0.235050 The estimated coefficient for the intercept is always given under the name “(Intercept)”. Estimated coefficients for independent variables are given based on their column names in the original data (“ht” here, for \\(\\beta_1\\), or the estimated increase in expected weight for a one unit increase in height). You can also pull out the residuals from the model fit: head(residuals(mod_a)) ## 1 2 3 4 5 6 ## 0.05820415 -0.82693141 -0.08223993 0.48644436 -0.46920621 -0.06405608 This is a vector the same length as the number of observations (rows) in the dataframe you used to fit the model. The residuals are in the same order as the observations in the original dataframe. You can use the coef results to plot a regression line based on the model fit on top of points showing the original data: mod_coef &lt;- coef(mod_a) ggplot(nepali, aes(x = ht, y = wt)) + geom_point(size = 0.2) + xlab(&quot;Height (cm)&quot;) + ylab(&quot;Weight (kg)&quot;) + geom_abline(aes(intercept = mod_coef[1], slope = mod_coef[2]), col = &quot;blue&quot;) The summary() function gives you a lot of information about the model: summary(mod_a) ## ## Call: ## lm(formula = wt ~ ht, data = nepali) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.44736 -0.55708 0.01925 0.49941 2.73594 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -8.694768 0.427398 -20.34 &lt;2e-16 *** ## ht 0.235050 0.005257 44.71 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9017 on 183 degrees of freedom ## (15 observations deleted due to missingness) ## Multiple R-squared: 0.9161, Adjusted R-squared: 0.9157 ## F-statistic: 1999 on 1 and 183 DF, p-value: &lt; 2.2e-16 The object created when you use the summary() function on an lm object has several different parts you can pull out using the $ operator: names(summary(mod_a)) ## [1] &quot;call&quot; &quot;terms&quot; &quot;residuals&quot; &quot;coefficients&quot; ## [5] &quot;aliased&quot; &quot;sigma&quot; &quot;df&quot; &quot;r.squared&quot; ## [9] &quot;adj.r.squared&quot; &quot;fstatistic&quot; &quot;cov.unscaled&quot; &quot;na.action&quot; summary(mod_a)$coefficients ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -8.694768 0.427397843 -20.34350 7.424640e-49 ## ht 0.235050 0.005256822 44.71334 1.962647e-100 You can use plot with an lm object to get a number of useful diagnostic plots to check regression assumptions: plot(mod_a) You can also use binary variables or factors as independent variables in regression models: mod_b &lt;- lm(wt ~ sex, data = nepali) summary(mod_b)$coefficients ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.497980 0.3110957 33.745177 1.704550e-80 ## sexFemale -0.674724 0.4562792 -1.478752 1.409257e-01 This call fits the model: \\[ Y_{i} = \\beta_{0} + \\beta_{1}X_{1,i} + \\epsilon_{i} \\] where \\(X_{1,i}\\) : sex of child \\(i\\), where 0 = male; 1 = female 3.5.3 Generalized linear models (GLMs) You can fit a variety of models, including linear models, logistic models, and Poisson models, using generalized linear models (GLMs). For linear models, the only difference between lm and glm is how they’re fitting the model (least squares versus maximum likelihood). You should get the same results regardless of which you pick. For example: mod_c &lt;- glm(wt ~ ht, data = nepali) summary(mod_c)$coef ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -8.694768 0.427397843 -20.34350 7.424640e-49 ## ht 0.235050 0.005256822 44.71334 1.962647e-100 summary(mod_a)$coef ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -8.694768 0.427397843 -20.34350 7.424640e-49 ## ht 0.235050 0.005256822 44.71334 1.962647e-100 You can fit other model types with glm() using the family option: Model type family option Linear family = gaussian(link = 'identity') Logistic family = binomial(link = 'logit') Poisson family = poisson(link = 'log') For example, say we wanted to fit a logistic regression for the nepali data of whether the probability that a child weighs more than 13 kg is associated with the child’s height. First, create a binary variable for wt_over_13: nepali &lt;- nepali %&gt;% mutate(wt_over_13 = wt &gt; 13) head(nepali) ## id sex wt ht age wt_over_13 ## 1 120011 Male 12.8 91.2 41 FALSE ## 2 120012 Female 14.9 103.9 57 TRUE ## 3 120021 Female 7.7 70.1 8 FALSE ## 4 120022 Female 12.1 86.4 35 FALSE ## 5 120023 Male 14.2 99.4 49 TRUE ## 6 120031 Male 13.9 96.4 46 TRUE Now you can fit a logistic regression: mod_d &lt;- glm(wt_over_13 ~ ht, data = nepali, family = binomial(link = &quot;logit&quot;)) summary(mod_d)$coef ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -32.7016520 5.85196755 -5.588147 2.295060e-08 ## ht 0.3495227 0.06331892 5.520036 3.389307e-08 Here, the model coefficient gives the log odds of having a weight higher than 13 kg associated with a unit increase in height. There are some conventions that can be used in R formulas. Common ones include: Convention Meaning I() calculate the value inside before fitting (e.g., I(x1 + x2)) : fit the interaction between two variables (e.g., x1:x2) * fit the main effects and interaction for both variables (e.g., x1*x2 equals x1 + x2 + x1:x2) . fit all variables other than the response (e.g., y ~ .) - do not include a variable (e.g., y ~ . - x1) 1 intercept (e.g., y ~ 1) 3.5.4 References– statistics in R A great (and free for CSU students) resource to find out more about using R for basic statistics: Introductory Statistics with R If you want all the details about fitting linear models and GLMs in R, Faraway’s books are fantastic: Linear Models with R (also freely available through our library) Extending the Linear Model with R 3.6 In-course exercise 3.6.1 Loading data from an R package The data we’ll be using today is from a dataset called worldcup in the package faraway. Load that data so you can use it on your computer (note: you will need to load and install the faraway package to do this). Use the help file for the data to find out more about the dataset. Use some basic functions, like head, tail, colnames, str, and summary to check out the data a bit. See if you can figure out: What variables are included in this dataset? (Check the column names.) What class is each column currently? In particular, which are numbers and which are factors? 3.6.1.1 Example R code: Load the faraway package using load() and then load the data using data(): ## Uncomment the next line if you need to install the package # install.packages(&quot;faraway&quot;) library(faraway) data(&quot;worldcup&quot;) Check out the help file for the worldcup dataset to find out more about the data. (Note: Only datasets that are parts of packages will have help files.) ?worldcup Check out the data a bit: str(worldcup) ## &#39;data.frame&#39;: 595 obs. of 7 variables: ## $ Team : Factor w/ 32 levels &quot;Algeria&quot;,&quot;Argentina&quot;,..: 1 16 9 9 5 32 11 11 18 20 ... ## $ Position: Factor w/ 4 levels &quot;Defender&quot;,&quot;Forward&quot;,..: 4 4 1 4 2 2 1 2 4 1 ... ## $ Time : int 16 351 180 270 46 72 138 33 21 103 ... ## $ Shots : int 0 0 0 1 2 0 0 0 5 0 ... ## $ Passes : int 6 101 91 111 16 15 51 9 22 38 ... ## $ Tackles : int 0 14 6 5 0 0 2 0 0 1 ... ## $ Saves : int 0 0 0 0 0 0 0 0 0 0 ... head(worldcup) ## Team Position Time Shots Passes Tackles Saves ## Abdoun Algeria Midfielder 16 0 6 0 0 ## Abe Japan Midfielder 351 0 101 14 0 ## Abidal France Defender 180 0 91 6 0 ## Abou Diaby France Midfielder 270 1 111 5 0 ## Aboubakar Cameroon Forward 46 2 16 0 0 ## Abreu Uruguay Forward 72 0 15 0 0 tail(worldcup) ## Team Position Time Shots Passes Tackles Saves ## van Bommel Netherlands Midfielder 540 2 307 31 0 ## van Bronckhorst Netherlands Defender 540 1 271 10 0 ## van Persie Netherlands Forward 479 14 108 1 0 ## von Bergen Switzerland Defender 234 0 79 3 0 ## Alvaro Pereira Uruguay Midfielder 409 6 140 17 0 ## Ozil Germany Midfielder 497 7 266 3 0 colnames(worldcup) ## [1] &quot;Team&quot; &quot;Position&quot; &quot;Time&quot; &quot;Shots&quot; &quot;Passes&quot; &quot;Tackles&quot; ## [7] &quot;Saves&quot; summary(worldcup) ## Team Position Time Shots ## Slovakia : 21 Defender :188 Min. : 1.0 Min. : 0.000 ## Uruguay : 21 Forward :143 1st Qu.: 88.0 1st Qu.: 0.000 ## Argentina: 20 Goalkeeper: 36 Median :191.0 Median : 1.000 ## Cameroon : 20 Midfielder:228 Mean :208.9 Mean : 2.304 ## Chile : 20 3rd Qu.:270.0 3rd Qu.: 3.000 ## Paraguay : 20 Max. :570.0 Max. :27.000 ## (Other) :473 ## Passes Tackles Saves ## Min. : 0.00 Min. : 0.000 Min. : 0.0000 ## 1st Qu.: 29.00 1st Qu.: 1.000 1st Qu.: 0.0000 ## Median : 61.00 Median : 3.000 Median : 0.0000 ## Mean : 84.52 Mean : 4.192 Mean : 0.6672 ## 3rd Qu.:115.50 3rd Qu.: 6.000 3rd Qu.: 0.0000 ## Max. :563.00 Max. :34.000 Max. :20.0000 ## 3.6.2 Basic plots of the data Use some basic plots to check out this data. Try the following: Plot histograms of all the numeric variables (Time, Shot, Passes, Tackles, Saves) Plot scatterplots of different combinations of numeric variables (e.g., Time vs. Shots). Try doing this using the geom_point() geom from ggplot2. Also try doing it using the ggpairs() function from the GGally package, to plot several of these at the same time. Try using different constant or mapped values with the color aesthetic. Create boxplots of Time, Shots, Passes and Saves by position. Go online and find out which teams were the top four teams in this World Cup (i.e., first through fourth places). Create a top_teams subset with just these teams. Plot boxplots of Shots and Saves by team for just these teams. Did you notice any interesting features of the data when you did any of the graphs in this section? 3.6.2.1 Example R code: Use histograms to explore the distribution of different variables. If you want to change the number of bins in the histogram, try playing around with the bins and binwidth arguments. You can use the bins argument to say how many bins you want (e.g., bins = 50). You can use the binwidth argument to say how wide you want the bins to be (e.g., binwidth = 10 if you wanted bins to be 10 units wide, in the units of the variable mapped to the x aesthetic. Try using fill and color to change the appearance of the plot. Google “R colors” and search the images to find links to listings of different R colors. library(ggplot2) ggplot(worldcup, aes(x = Time)) + geom_histogram() ggplot(worldcup, aes(x = Time)) + geom_histogram(bins = 50) ggplot(worldcup, aes(x = Time)) + geom_histogram(binwidth = 100) ggplot(worldcup, aes(x = Time)) + geom_histogram(binwidth = 50, color = &quot;white&quot;, fill = &quot;cyan4&quot;) Create a scatterplot of Time versus Passes. To change the size of the points, use the size argument (use a number lower than 1 for smaller points, higher than 1 for larger points). Try changing the color and transparency of the points using the aesthetics color and alpha. Try using color to show each player’s position by mapping Position to the color aesthetic. ggplot(worldcup, aes(x = Time, y = Passes)) + geom_point() ggplot(worldcup, aes(x = Time, y = Passes)) + geom_point(size = 0.5) ggplot(worldcup, aes(x = Time, y = Passes)) + geom_point(size = 2, color = &quot;blue&quot;, alpha = 0.25) ggplot(worldcup, aes(x = Time, y = Passes, color = Position)) + geom_point() Use the ggpairs function from the GGally package to plot scatterplots of all combinations of several numeric variables. library(GGally) library(dplyr) ggpairs(select(worldcup, Time, Shots, Passes, Tackles, Saves)) To create a boxplot of Shots by Position, you can use geom_boxplot: ggplot(worldcup, aes(x = Position, y = Shots)) + geom_boxplot() The top four teams in this World Cup were Spain, the Netherlands, Germany, and Uruguay. Create a subset with just the data for these four teams: top_teams &lt;- worldcup %&gt;% filter(Team %in% c(&quot;Spain&quot;, &quot;Netherlands&quot;, &quot;Germany&quot;, &quot;Uruguay&quot;)) %&gt;% mutate(Team = factor(Team)) This dataset will still have all the levels saved for the Team factor, even though it isn’t using them all. You can re-set this by resetting Team as a factor, which is what I’ve done with the mutate line. When R creates a factor from a vector, its default is to only use as levels the values that show up in the vector. Now, you can plot the boxplots, mapping Team to the x aesthetic and Shots or Saves to the y aesthetic: ggplot(top_teams, aes(x = Team, y = Shots)) + geom_boxplot() + ggtitle(&quot;Shots&quot;) ggplot(top_teams, aes(x = Team, y = Saves)) + geom_boxplot() + ggtitle(&quot;Saves&quot;) 3.6.2.2 If you have extra time: If you wanted to do the same plot for several different variables, you could loop through your code (we’ll be covering more about loops in a few weeks). For example, you could create histograms for all of the numeric variables (if you do this in RStudio, you’ll need to use the arrows on the plot window to move through and see all the different plots once you’ve created them): ## Create an object with the column names for all of the numeric variables my_vars &lt;- colnames(worldcup)[3:7] ## Loop through all of those variables. Print out a histogram with the ## variable, and have it print on the plot, as the main title, the ## column name for that variable for(var in my_vars){ worldcup$to_plot &lt;- worldcup[ , var] a &lt;- ggplot(worldcup, aes(x = to_plot)) + geom_histogram(bins = 20, color = &quot;white&quot;, fill = &quot;navy&quot;) + xlab(var) + ggtitle(paste(&quot;Histogram of&quot;, var)) plot(a) } A few things to note in this example: To map an element of the data to an aesthetic, it’s easiest if that element is saved in a column in the dataframe. Within this loop, I’m making an extra column called to_plot, where I’m copying the column of the variable I want to plot each time the loop runs. That way, I can always use x = to_plot in the aesthetic mapping for the ggplot object. If you run code to create a ggplot object within a loop, it won’t automatically print. Instead, you need to use print to get the object to print out. One way to do that is to save the final ggplot object as an R object (here I’m saving it to a) and then use the print function to print that object. Next week, we’ll talk some about faceting, which can create multiple plots by variable like this in a lot less code. However, it’s useful at this point to start thinking about how to extend code to use in loops, to save yourself time when you need to repeat something similar many times. 3.6.3 Exploring the data using simple statistics and logical statements Next, try checking out the data using some basic commands for simple statistics, like mean(), range(), max(), and min(). Use these, along with some logical statements, to help you answer the following questions: What is the range of time that players spent in the game? Who played the most World Cup time in this World Cup? For the minimum of the range of Time, how many players played this amount of time? What is the mean number of saves that players made? What is the mean number of saves just among the goalkeepers? How many of the players are goalkeepers? Did any non-goalkeeper make a save? 3.6.3.1 Example R code: Use range() to find out the range of time these players played in the World Cup. range(worldcup$Time) ## [1] 1 570 To figure out who played the most time, you need to subset out the rows of the dataset where the Time variable equals the maximum of the Time variable for the whole dataset. There are a few ways to do that. Here I’m showing two: (1) using logic within the “square-bracket indexing”, to pull out just rows where it is TRUE that the Time for that row equals max(worldcup$Time) and (2) using filter from the dplyr package to filter down to rows where where it is TRUE that the Time for that row equals max(Time) for the whole dataset. max(worldcup$Time) ## [1] 570 head(worldcup$Time == max(worldcup$Time)) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE worldcup[worldcup$Time == max(worldcup$Time), ] ## Team Position Time Shots Passes Tackles Saves to_plot ## Arevalo Rios Uruguay Midfielder 570 5 195 21 0 0 ## Maxi Pereira Uruguay Midfielder 570 5 182 15 0 0 ## Muslera Uruguay Goalkeeper 570 0 75 0 16 16 worldcup %&gt;% filter(Time == max(Time)) ## Team Position Time Shots Passes Tackles Saves to_plot ## 1 Uruguay Midfielder 570 5 195 21 0 0 ## 2 Uruguay Midfielder 570 5 182 15 0 0 ## 3 Uruguay Goalkeeper 570 0 75 0 16 16 Note: You may have noticed that you lost the players names when you did this using the dplyr pipechain. That’s because dplyr functions convert the data to a dataframe format that does not include rownames. If you want to keep players’ names, use mutate to move those names from the rownames of the data into a column in the dataframe: worldcup %&gt;% mutate(Name = rownames(worldcup)) %&gt;% filter(Time == max(Time)) ## Team Position Time Shots Passes Tackles Saves to_plot Name ## 1 Uruguay Midfielder 570 5 195 21 0 0 Arevalo Rios ## 2 Uruguay Midfielder 570 5 182 15 0 0 Maxi Pereira ## 3 Uruguay Goalkeeper 570 0 75 0 16 16 Muslera To calculate the mean number of saves among all the players, use the mean function, either by itself or within a summarize call: mean(worldcup$Saves) ## [1] 0.6672269 worldcup %&gt;% summarize(mean_saves = mean(Saves)) ## mean_saves ## 1 0.6672269 For the next parts of the question, it will be convenient to have a logical vector for whether each player is a goalkeeper, so here’s how you would create that: goalie &lt;- worldcup$Position == &quot;Goalkeeper&quot; This new object, goalie, is a vector the same length as worldcup$Position. Each element of goalie says whether it is TRUE or FALSE that worldcup$Position is equal to “Goalkeeper” at that spot on the worldcup$Position vector. head(goalie) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE The summary() function will count up the total number of times that goalie is TRUE and FALSE. summary(goalie) ## Mode FALSE TRUE NA&#39;s ## logical 559 36 0 There are a few ways to use this vector to figure out how many players were goalkeepers. First, you could use summary (which I just showed) or table, and just read how many times this vector has the value TRUE. Second, since R saves logical vectors with TRUE as 1 and FALSE as 0, you could just the sum function to add up the vector to find out how often it’s TRUE (sum adds up every value in the vector). table(goalie) ## goalie ## FALSE TRUE ## 559 36 sum(goalie) ## [1] 36 You could also answer this question by using summarize from dplyr. You need to group_by player position and then you can use the n function in summarize to count up the total number of observations in each group: worldcup %&gt;% group_by(Position) %&gt;% summarize(n_players = n()) ## # A tibble: 4 × 2 ## Position n_players ## &lt;fctr&gt; &lt;int&gt; ## 1 Defender 188 ## 2 Forward 143 ## 3 Goalkeeper 36 ## 4 Midfielder 228 Now, you can answer the questions about mean saves for goalies and max saves for non-goalies. First, try doing that using the goalie logical vector you created. If you put goalie in the square bracket indexing for the dataframe as the rows value (i.e., the index before the comma), R will subset out just the rows where goalie is equal to TRUE. If you put !goalie in the square bracket indexing as the rows value, R will just subset out the rows where goalie is equal to FALSE. You can use this index subsetting to figure out the mean number of saves per goalie and also whether any non-goalie made a save (by checking the maximum value or range of saves for non-goalies). head(worldcup[goalie, ]) ## Team Position Time Shots Passes Tackles Saves to_plot ## Barry Ivory Coast Goalkeeper 270 0 23 0 8 8 ## Benaglio Switzerland Goalkeeper 270 0 75 0 11 11 ## Bravo Chile Goalkeeper 360 0 58 0 4 4 ## Buffon Italy Goalkeeper 45 0 4 0 0 0 ## Casillas Spain Goalkeeper 540 0 67 0 11 11 ## Chaouchi Algeria Goalkeeper 90 0 17 0 2 2 mean(worldcup[goalie, &quot;Saves&quot;]) ## [1] 11.02778 range(worldcup[!goalie, &quot;Saves&quot;]) ## [1] 0 0 You could also answer this quesiton using a dplyr pipe chain to summarize the data after grouping it by position: worldcup %&gt;% group_by(Position) %&gt;% summarize(number_players = n(), mean_saves = mean(Saves), max_saves = max(Saves)) ## # A tibble: 4 × 4 ## Position number_players mean_saves max_saves ## &lt;fctr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Defender 188 0.00000 0 ## 2 Forward 143 0.00000 0 ## 3 Goalkeeper 36 11.02778 20 ## 4 Midfielder 228 0.00000 0 3.6.4 Using regression models to explore data For this part of the exercise, you’ll use a dataset on weather, air pollution, and mortality counts in Chicago, IL. This dataset is called chicagoNMMAPS and is part of the dlnm package. Change the name of the dataframe to something shorter, like chic. Check out the data a bit to see what variables you have, and then perform the following tasks: Write out (on paper, not in R) the regression equation for regressing dewpoint temperature on temperature. Try fitting a linear regression of dew point temperature (dptp) on temperature (temp). (Bonus points: Notice anything that seems unusual about these two variables in this dataset? You can find out with summary, but it helps if you know a bit about what dewpoint temperature measures.) Save this model as the object mod_1. Based on this regression, does there seem to be a relationship between temperature and dewpoint temperature in Chicago? (Hint: Try using summary() on the model object to get more information about the model you fit.) What is the p-value for the coefficient for temperature? Plot temperature (x-axis) versus dewpoint temperature (y-axis) for Chicago. Add in the regression line from the model you fit. Use plot() on the model object to check if some of the assumptions for the regression model seem appropriate. Try fitting the regression as a GLM, using glm(). Are your coefficients different? Does \\(PM_{10}\\) vary by day of the week? (Hint: The dow variable is a factor that gives day of the week. You can do an ANOVA analysis by fitting a linear model using this variable as the independent variable, and then run anova() on that model, and R will compare it to an intercept-only model.) What day of the week is PM10 generally highest? (Check the model coefficients to figure this out.) Try to write out (on paper) the regression equation for the model you’re fitting. Try using glm() to run a Poisson regression of respiratory deaths (resp) on temperature during summer days. Start by creating a subset with just summer days called summer. (Hint: Use the month variable to do this– just pull out the subset where the month is 6, 7, or 8, for June, July, and August.) Try to write out the regression equation for the model you’re fitting. The coefficient for the temperature variable in this model is our best estimate (based on this model) of the log relative risk for a one degree Celcius increase in temperature. What is the relative risk associated with a one degree Celsius increase? 3.6.4.1 Example R code: Install and load the dlnm package and then load the chicagoNMMAPS data. Change the name of the dataframe to chic, so it will be shorter to call for the rest of your work. # install.packages(&quot;dlnm&quot;) library(dlnm) data(&quot;chicagoNMMAPS&quot;) chic &lt;- chicagoNMMAPS Fit a linear regression of dptp on temp and save as the object mod_1: mod_1 &lt;- lm(dptp ~ temp, data = chic) mod_1 ## ## Call: ## lm(formula = dptp ~ temp, data = chic) ## ## Coefficients: ## (Intercept) temp ## 24.025 1.621 Use summary() to check out a bit more about the model you fit. summary(mod_1) ## ## Call: ## lm(formula = dptp ~ temp, data = chic) ## ## Residuals: ## Min 1Q Median 3Q Max ## -24.3093 -3.7470 0.4687 4.0738 18.6518 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 24.024869 0.112933 212.7 &lt;2e-16 *** ## temp 1.620650 0.007631 212.4 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.899 on 5112 degrees of freedom ## Multiple R-squared: 0.8982, Adjusted R-squared: 0.8982 ## F-statistic: 4.511e+04 on 1 and 5112 DF, p-value: &lt; 2.2e-16 There does seem to be an association between temperature and dewpoint temperature: a unit increase in temperature is associated with a 1.6 unit increase in dewpoint temperature. The p-value for the temperature coefficient is &lt;2e-16. This is far below 0.05, which suggests we would be very unlikely to see such a strong association by chance if the null hypothesis, that the two variables are not associated, were true. Plot these two variables and add in the regression line from the model (note: I’ve used the color option to make the color of the points gray). Use the values from coef with a geom_abline to add the regression line for the model you fit. mod_coefs &lt;- coef(mod_1) ggplot(chic, aes(x = temp, y = dptp)) + geom_point(size = 0.5, col = &quot;gray&quot;) + geom_abline(aes(intercept = mod_coefs[1], slope = mod_coefs[2])) Plot some plots to check model assumptions for the model you fit using the plot() function on your model object: par(mfrow = c(2, 2)) # Set to four plots per panel -- 2 rows, 2 columns plot(mod_1) par(mfrow = c(1, 1)) # Reset to one plot per panel Try fitting the model using glm(). Call it mod_1a. Compare the coefficients for the two models. You can use the coef() function on an lm or glm object to pull out just the model coefficients. mod_1a &lt;- glm(dptp ~ temp, data = chic) coef(mod_1) ## (Intercept) temp ## 24.02487 1.62065 coef(mod_1a) ## (Intercept) temp ## 24.02487 1.62065 The results from the two models are identical. Fit a model of \\(PM_{10}\\) regressed on day of week, where day of week is a factor. mod_2 &lt;- lm(pm10 ~ dow, data = chic) summary(mod_2) ## ## Call: ## lm(formula = pm10 ~ dow, data = chic) ## ## Residuals: ## Min 1Q Median 3Q Max ## -39.05 -12.55 -3.34 8.80 328.66 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 27.5217 0.7303 37.684 &lt; 2e-16 *** ## dowMonday 6.1322 1.0340 5.931 3.22e-09 *** ## dowTuesday 6.7954 1.0269 6.617 4.05e-11 *** ## dowWednesday 8.4768 1.0262 8.261 &lt; 2e-16 *** ## dowThursday 8.8047 1.0240 8.598 &lt; 2e-16 *** ## dowFriday 9.4816 1.0262 9.240 &lt; 2e-16 *** ## dowSaturday 3.6602 1.0269 3.564 0.000368 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 19.07 on 4856 degrees of freedom ## (251 observations deleted due to missingness) ## Multiple R-squared: 0.02588, Adjusted R-squared: 0.02467 ## F-statistic: 21.5 on 6 and 4856 DF, p-value: &lt; 2.2e-16 Use the anova() command to compare this model to a model with only an intercept (i.e., one that only fits a global mean and uses that as the expected value for all of the observations). anova(mod_2) ## Analysis of Variance Table ## ## Response: pm10 ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## dow 6 46924 7820.6 21.5 &lt; 2.2e-16 *** ## Residuals 4856 1766407 363.8 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The p-value for an ANOVA of the model with day-of-week coefficients versus the model that just has an intercept is &lt; 2.2e-16. This is well below 0.05, which suggests that day-of-week is associated with PM10 concentration, as a model that includes day-of-week does a much better job of explaining variation in PM10 than a model without it does. (Note, too, that the F value and Pr(&gt;F) for the anova() call are identical to the F-statistic information given in the summary() of the model object. This will always be true when you’re using anova() to compare a model to a model with just an intercept.) Use a boxplot to visually compare PM10 by day of week. ggplot(chic, aes(x = dow, y = pm10)) + geom_boxplot() Now try the same plot, but try using the ylim = option to change the limits on the y-axis for the graph, so you can get a better idea of the pattern by day of week (some of the extreme values are very high, which makes it hard to compare by eye when the y-axis extends to include them all). ggplot(chic, aes(x = dow, y = pm10)) + geom_boxplot() + ylim(c(0, 100)) ## Warning: Removed 292 rows containing non-finite values (stat_boxplot). Create a subset called summer with just the summer days: summer &lt;- chic %&gt;% filter(month %in% 6:8) Use glm() to fit a Poisson model of respiratory deaths regressed on temperature. Since you want to fit a Poisson model, use the option family = poisson(link = &quot;log&quot;). mod_3 &lt;- glm(resp ~ temp, data = summer, family = poisson(link = &quot;log&quot;)) summary(mod_3) ## ## Call: ## glm(formula = resp ~ temp, family = poisson(link = &quot;log&quot;), data = summer) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -3.9755 -0.7162 -0.1807 0.6927 3.6555 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 1.910317 0.058373 32.726 &lt;2e-16 *** ## temp 0.006137 0.002581 2.378 0.0174 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 1499.4 on 1287 degrees of freedom ## Residual deviance: 1493.8 on 1286 degrees of freedom ## AIC: 6425.4 ## ## Number of Fisher Scoring iterations: 4 Use the fitted model coefficient to determine the relative risk for a one degree Celcius increase in temperature. First, remember that you can use the coef() function to read out the model coefficients. The second of these is the value for the temperature coefficient. That means that you can use indexing ([2]) to get just that value. That’s the log relative risk; take the exponent to get the relative risk. coef(mod_3) ## (Intercept) temp ## 1.910316958 0.006136743 coef(mod_3)[2] ## temp ## 0.006136743 exp(coef(mod_3)[2]) ## temp ## 1.006156 "],
["appendix-a-vocabulary.html", "A Appendix A: Vocabulary A.1 Week 1 A.2 Week 2 A.3 Week 3 A.4 Week 4 A.5 Week 5 A.6 Week 6 A.7 Week 7 A.8 Week 8", " A Appendix A: Vocabulary You will be responsible for knowing the following functions and vocabulary for the weekly quizzes. A.1 Week 1 c() data.frame() dim() ncol() nrow() head(), option n = read.csv, options head =, skip =, nrow = [...], [..., ...] getwd() setwd(), including setwd(&quot;~&quot;) list.files() install.packages() library() &lt;- = subset() length() open source software “free as in beer” “free as in speech” CRAN GitHub R packages R working directory How to download a csv file from GitHub Nate Silver FiveThirtyEight Grading policies for the course Course requirements / policies for in-class quizzes and weekly journal entries Style rules for naming R objects Difference between R and RStudio Vectors Dataframes Note: Pay attention in the course notes and exercise to where the code uses quotation marks and where it does not– this will help you in the quiz A.2 Week 2 source() setwd(), including setwd(&quot;~&quot;), setwd(&quot;..&quot;), setwd(&quot;..\\..&quot;) list.files(), option path = functions in the read.table() family, including read.csv() and read.delim(). What are defaults of the sep = and dec = options for each? For all, the options header =, sep =, as.is =, na.strings =, nrows =, skip =, and col.names =. The tidyverse functions in the read_* family (e.g., read_csv) Advantages of the read_* family of functions compared to their base R analogues (the read.table functions) paste(), option sep = paste0() readxl package and its read_excel() function haven package and its read_sas() function $ class() str() as.Date(), option format = lubridate functions, include ymd, ymd_hm, and mdy range() dplyr package rename() mutate() arrange() %&gt;%, advantages of piping filter() Reading in data from either a local or online flat file save(), option file = load() rm() ls() Main types of vector classes in R: character, numeric, factor, date, logical Which classes of vectors don’t always look like numbers, but R assigns an underlying numeric value to? (Hint: This include the logical class, which R saves with an underlying number, with TRUE = 1 and FALSE = 0.) Common abbreviations for telling R date formats (e.g., “%m”, “%y”) Common logical expressions to use in filter() relative pathnames absolute pathnames delimited files fixed width files R script file (How would you make a new one? What file extension would it have? Why is it important to use? How do you run code from a script file in RStudio?) What kinds of data can be read into R? How to read flat files of data that are online directly into R if they are on: A “http:” site A “https:” site When you might want to save an R object as a .RData file and when (and why) you might not want to A.3 Week 3 data() (with and without the name of a dataset as an option) library() (with and without an argument in the parentheses) hist() plot() pairs() boxplot() (both for a single numeric variable and for a numeric vector stratified by a factor) common options for all these plotting functions: main =, xlab =, ylab =, xlim =, ylim =, col =, cex = with() range() min() max() mean() median() table() cor(), both for two variables in a dataframe, and to get the correlation matrix for several variables in a dataframe summary(), as applied to: different classes of vectors (numeric, factor, logical), dataframes, lm objects, and glm objects lm(), data= option glm(), options data=, family= Functions to apply to a lm or glm object: summary(), coef(), residuals(), fitted(), plot(), abline() The following elements that you can pull from the summary of a lm call: summary(mod_1)$call, summary(mod_1)$coef, summary(mod_1)$r.squared, summary(mod_1)$cov.unscaled How to create a logical vector and how to use one to (1) index a data frame and (2) count the number of times a certain condition is true in a vector What the bang operator (!) does to a logical operator What to do if you want to apply a summary statistic function to a vector with missing values (you do not need to know every option name for all the functions, just know that you would need to include an option like na.rm= or use=, and that you can use the help file for a function to figure out the option call for that function). Are there any circumstances where I (or Google) would recommend you use attach() and detach()? The following about object-oriented programming: In R, it means that some functions, like summary() and plot(), will do different things depending on what type of object you call it on. The basic structure of regression formulae in R (for example, y ~ x1 + x2) Difference between using lm() and glm() to fit a linear regression model Difference between the code you would use to fit a linear, Poisson, or logistic model using glm() Make sure you understand the difference in what you’d get for plot(x, y, data = my_data) and plot(lm(y ~ x, data = my_data)) A.4 Week 4 Guidelines for good graphics Data density / data-to-ink ratio Small multiples Edward Tufte Hadley Wickham differences between ggplot and R base graphics (you’re just responsible for knowing the ones listed in the lecture notes) Where to put the + in ggplot statements to avoid problems (ends of lines instead of starts of new lines) Can you save a ggplot object as an R object that you can reference later? If so, how would you add elements on to that object? How would you print it when you were ready to print the graph to your RStudio graphics window? ggplot() function, including aes() part of the call geom_point(), geom_line() geom_histogram() geom_hline(), geom_vline() geom_text() xlab(), ylab(), xlim(), ylim(), ggtitle() facet_grid() gridExtra package, including grid.arrange() and facet_wrap() ggthemes package, including theme_few() and theme_tufte() Setting point color for geom_point() both as a constant (all points red) and as a way to show the level of a factor for each observation size, alpha, color Re-naming and re-ordering factors Note: If you read this and find and bring in an example of a “small multiples” graph (from a newspaper, a website, an academic paper), you can get one extra point on this quiz A.5 Week 5 as.Date, including format= option format applied to Date objects (including what class the output of this function will be) Reproducible research, including what it is and advantages to aiming to make your research reproducible R style guidelines on variable names, attach(), &lt;- vs. =, line length, spacing, semicolons, commenting, indentation, and code grouping Markup languages (concept and examples) Basic conventions for Markdown (bold, italics, links, headers, lists) Literate programming What working directory R uses for code in an .Rmd document Basic syntax for RMarkdown chunks, including how to name them Options for RMarkdown chunks: echo, eval, messages, warnings, include, fig.width, fig.height, results Difference between global options and chunk options, and which takes precendence What inline code is and how to write it in RMarkdown How to set global options Why style is important in coding RPubs A.6 Week 6 with() Three characteristics of tidy data Five common problems with tidy data and how to resolve them (make sure you understand the examples shown, which you can find out more about in the Hadley Wickham paper I reference) select() filter() mutate() summarize() group_by() arrange() gather() spread() %&gt;% Go through the examples where I’ve chained together several functions to clean up a dataset and make sure you can follow through these chained examples A.7 Week 7 for loops basics of writing a function figuring out the output of a loop based on its code figuring the the output of a function based on its code parentheses around a full assignment statement (e.g., (ex &lt;- 1)) in-class exercise and example analysis from Oct. 12 course kable() from the knitr package A.8 Week 8 apply family of functions *_join family of functions matrix objects, including how to subset list objects, including how to subset Titanic example analysis from Oct. 19 course Using color =, size =, or shape = in the aes() statement of a ggplot() call geom_bar() geom_smooth(), including the se = and method = options jittering, the position = position_jitter() option in ggplot geoms "],
["appendix-b-homework.html", "B Appendix B: Homework B.1 Homework #1 B.2 Homework #2 B.3 Homework #3 B.4 Homework #4 B.5 Homework #5 B.6 Homework #6", " B Appendix B: Homework The following are six homework assignments for the course. B.1 Homework #1 Due date: Sept. 14 For your first homework assignment, you’ll be working through a few swirl lessons that are relevant to the material we’ve covered so far. Swirl is a platform that helps you learn R in R - you can complete the lessons right in your R console. B.1.1 Getting started First, you’ll need to install the swirl package: install.packages(&quot;swirl&quot;) Next, load the swirl package. We’re going to download a course from swirl’s course repository called R Programming E using the function install_course_github. Then call the swirl() function to enter the interactive platform: library(swirl) uninstall_course(&quot;R_Programming_E&quot;) # Only run if you have an old version of # R_Programming_E installed install_course_github(&quot;swirldev&quot;, &quot;R_Programming_E&quot;) swirl() After calling swirl(), you may be prompted to clear your workspace variables by running rm=(list=ls()). Running this code will clear any variables you already have saved in your global environment. While swirl recommends that you do this, it’s not necessary. B.1.2 Swirl lessons Sign in with your name, and choose R Programming E when swirl asks you to choose a course. For this homework, you will need to work through the following lessons in that course (the lesson number is in parentheses): Basic Building Blocks (1) Vectors (4) Missing Values (5) Subsetting Vectors (6) Logic (8) Looking at Data (12) Dates and Times (14) Each lesson should take about 10-15 minutes, but some are much shorter. You can complete the lessons in any order you want, but you may find it easiest to start with the lowest-numbered lessons and work your way up, in the order we’ve listed the lessons here. You’ll be able to get started on some of these lessons after your first day in class (Basic Building Blocks, for example), but others cover topics that we’ll get to in weeks 2 and 3. Whether or not we’ve covered a swirl topic in class, you should be able to successfully work through the lesson. At the end of each lesson, you’ll be prompted to “inform someone about your successful completion of this lesson via email.” after answering 2 for ‘Yes,’ enter your full name, and enter rachel.severson@colostate.edu as the email address of the person you’d like to notify. You should be sending 7 emails in total. After telling swirl that you would like to send a notification email, an already-populated email should pop up with the lesson you just completed in the subject line - you just need to push send. This might not happen if you access your email through a web browser instead of an app. In this case, just send an email manually with a screenshot of the end of the lesson, and the name of the lesson you just completed. B.1.3 Special swirl commands In the swirl environment, knowing about the following commands will be helpful: Within each lesson, the prompt ... indicates that you should hit Enter to move on to the next section. play(): temporarily exit swirl. It can be useful during a swirl lesson to play around in the R console to try things out. nxt(): regain swirl’s attention after play()ing around in the console. main(): return to swirl’s main menu. bye(): exit swirl. Swirl will save your progress if you exit in the middle of a lesson. You can also hit the Esc. key to exit. (To re-enter swirl, run swirl(). In a new R session you will have to first load the swirl library: library(swirl).) B.1.3.1 For fun While they aren’t required for class, you should consider trying out some other swirl lessons later in the course. The Functions lesson, as well as lapply and sapply and vapply and tapply could be particularly useful. You can also look through the course directory to see what other courses and lessons are available. If you are doing extra swirl courses on your own, you probably want to do them through the “R Programming”, rather than the “R Programming E”, course, since you won’t need to let us know by email. To get this, you can run: library(swirl) install_course(&quot;R_Programming&quot;) swirl() B.2 Homework #2 Due date: Sept. 28 [R Markdown homework assignment] B.3 Homework #3 Due date: Oct. 12 [dplyr, tidy data homework assignment] B.4 Homework #4 Due date: Oct. 26 [Advanced R Markdown homework assignment] B.5 Homework #5 Due date: Nov. 9 [Homework on functions, regular expressions, and web data assignment] B.6 Homework #6 Due date: Nov. 30 [Mapping homework assignment] "],
["references.html", "References", " References "]
]
